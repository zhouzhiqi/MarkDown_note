{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类\" data-toc-modified-id=\"基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类</a></span></li><li><span><a href=\"#摘要\" data-toc-modified-id=\"摘要-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>摘要</a></span></li><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#绪论\" data-toc-modified-id=\"绪论-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>绪论</a></span><ul class=\"toc-item\"><li><span><a href=\"#SAR图像分类简介\" data-toc-modified-id=\"SAR图像分类简介-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>SAR图像分类简介</a></span></li><li><span><a href=\"#SAR图像分类的发展现状\" data-toc-modified-id=\"SAR图像分类的发展现状-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>SAR图像分类的发展现状</a></span></li><li><span><a href=\"#神经网络简介\" data-toc-modified-id=\"神经网络简介-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>神经网络简介</a></span></li><li><span><a href=\"#本文的研究内容和方法\" data-toc-modified-id=\"本文的研究内容和方法-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>本文的研究内容和方法</a></span></li><li><span><a href=\"#论文的结构安排\" data-toc-modified-id=\"论文的结构安排-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>论文的结构安排</a></span></li></ul></li><li><span><a href=\"#基于标准FCN神经网络的分割模型\" data-toc-modified-id=\"基于标准FCN神经网络的分割模型-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>基于标准FCN神经网络的分割模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#CNN卷积神经网络\" data-toc-modified-id=\"CNN卷积神经网络-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>CNN卷积神经网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#CNN基本原理\" data-toc-modified-id=\"CNN基本原理-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>CNN基本原理</a></span></li><li><span><a href=\"#CNN基本结构\" data-toc-modified-id=\"CNN基本结构-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>CNN基本结构</a></span></li></ul></li><li><span><a href=\"#基于FCN网络的图像分割\" data-toc-modified-id=\"基于FCN网络的图像分割-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>基于FCN网络的图像分割</a></span><ul class=\"toc-item\"><li><span><a href=\"#FCN网络的结构\" data-toc-modified-id=\"FCN网络的结构-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>FCN网络的结构</a></span></li><li><span><a href=\"#FCN网络的特点\" data-toc-modified-id=\"FCN网络的特点-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>FCN网络的特点</a></span></li></ul></li><li><span><a href=\"#本章小结\" data-toc-modified-id=\"本章小结-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>本章小结</a></span></li></ul></li><li><span><a href=\"#基于deeplab和内部边缘校正的神经网络的分割模型\" data-toc-modified-id=\"基于deeplab和内部边缘校正的神经网络的分割模型-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>基于deeplab和内部边缘校正的神经网络的分割模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#基于像素块的传统CRF模型\" data-toc-modified-id=\"基于像素块的传统CRF模型-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>基于像素块的传统CRF模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#传统potts先验CRF\" data-toc-modified-id=\"传统potts先验CRF-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>传统potts先验CRF</a></span></li><li><span><a href=\"#像素块特征提取\" data-toc-modified-id=\"像素块特征提取-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>像素块特征提取</a></span></li></ul></li><li><span><a href=\"#基于后置CRF的deeplab模型\" data-toc-modified-id=\"基于后置CRF的deeplab模型-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>基于后置CRF的deeplab模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#deeplab的CRF结构\" data-toc-modified-id=\"deeplab的CRF结构-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>deeplab的CRF结构</a></span></li><li><span><a href=\"#deeplab模型训练\" data-toc-modified-id=\"deeplab模型训练-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>deeplab模型训练</a></span></li></ul></li><li><span><a href=\"#基于边缘区域变换的DT网络\" data-toc-modified-id=\"基于边缘区域变换的DT网络-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>基于边缘区域变换的DT网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#DT-网络\" data-toc-modified-id=\"DT-网络-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>DT 网络</a></span></li><li><span><a href=\"#边缘区域变换算法\" data-toc-modified-id=\"边缘区域变换算法-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>边缘区域变换算法</a></span></li></ul></li><li><span><a href=\"#本章小结\" data-toc-modified-id=\"本章小结-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>本章小结</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类 \n",
    "\n",
    "研究生姓名:汤浩   \n",
    "学号:2014202120089   \n",
    "指导教师姓名、职称:何楚教授   \n",
    "专业名称:通信与信息系统   \n",
    "研究方向:图像分析与处理   \n",
    "\n",
    "Master Degree's Thesis Wuhan University   \n",
    "The Classification of SAR Images Based On Full Convolutional Network with Bayes Framework And Modification Of Explicit Edge Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 摘要\n",
    "\n",
    "合成孔径雷达(Synthetic Aperture Radar， SAR)信号相较于传统光学图像 \n",
    "信号具有高解析度，多通道的特点，主要用于民用的如农作物监测，灾害监测， \n",
    "军用的如地图绘制，军事侦察等。一般将SAR信号转化为对应多通道图像，利 \n",
    "用现有光学图像的方法来进行场景分类与标注，本文利用ESAR的Pauli分解伪 \n",
    "彩图，首先用传统的方法来分类，然后使用神经网络和边缘约束的方法，相较于 \n",
    "以前的方法提高了正确率，改善了边缘分布。\n",
    "\n",
    "在此之前经典的传统方法要进行超像素块的分割，块特征的提取，以及特征 \n",
    "分类器这三个步骤，均值平移(meanshift)或分水岭方法常用于超像素块的提取， \n",
    "分类器多采用支持向量机(Support Vector Machine， SVM)或多层网络(Back \n",
    "propagation network， BP)等，之后也引入了马尔科夫场(Markov Random filed， \n",
    "MRF)和条件随机场(conditional Random field，CRF)进一步考虑周围超像素 \n",
    "块的分类类别从而进一步提高了正确率。\n",
    "\n",
    "首先，以前的方法的分类器多使用传统如SVM， BP， logistic classifier等分 \n",
    "类器，这些分类器并不适合图像信号，为提高图像初始的分类正确率，引入全卷 \n",
    "积网络(fully convolutional network， FCN)网络中效果最好的FCN8作为分类 \n",
    "器，FCN8同时也负责卷积特征提取，同时FCN不需要用其他方法如meanshift \n",
    "来先将图像分块，再去针对区域处理，而是直接作用于单个像素点的RGB向量 \n",
    "上。\n",
    "\n",
    "然后，为了考虑周围像素分类类别的影响，同时考虑自身像素的分类类别， \n",
    "引入deeplab的全连接CRF综合考虑周围像素的类别先验信息，并用网格优化 \n",
    "法得到合适的CRF相关参数。FCN网络用于分割时边缘部分的像素点分类不准 \n",
    "确，这是反卷积和卷积的卷积核尺度决定的，在deeplab内部利用区域变换 \n",
    "(domain transform，DT)网络可稍微修正边缘像素点的分类结果，但效果不 \n",
    "显著，原DT算法存在很多问题，加w分析改进提出自己的改进DT扩散模型， \n",
    "在deepl油外部利用FCN边缘网络提取边缘信息，分别与DT的内部边缘网络 \n",
    "输出融合后输入DT中，然后与deeplab的结果进行外部融合，融合方法包括我 \n",
    "提出的改进DT的扩散法和补洞法。同时在内部和外部进行边缘融合最终可以将 \n",
    "分类结果边缘改善以及提高一定的正确率。\n",
    "\n",
    "最后在ESAR数据上进行了多方案的对比实验，分别为基于potts先验的标 \n",
    "准CRF或SVM分类模型并采取meanshift分割的方法，FCN8， deeplab 及 \n",
    "deeplab-DT和最终的deeplab-DT加FCN边缘网络融合的方法，实验表明毎一 \n",
    "种方案都比较以前的方案有一定提升，最终的边缘后置融合的方案效果最好，正 \n",
    "确率最高同时边缘修正的效果很好。\n",
    "\n",
    "**关键词**：合成孔径雷达，后置条件随机场，全卷积网络，边缘融合，改进区域变换模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Synthetic Aperture Radar (SAR)has many advantages such as high resolution and multichannel compared to the traditional optical image. It is used to accomplish civil purpose such as crop observation and disaster observation, and also military purpose such as map protraction and military scout. Classically, we transform SAR signals into optical image, and apply methods used for optical image to classify the category of diiferent objects or areas in SAR image. Our article use Pauli decomposition pseudo-image of ESAR, first we use traditional ways to classify and then apply methods of neural network and edge restriction, finally we raise the accuracy and improve the edge distribution compared to traditional methods.\n",
    "The classic way to classify SAR image need three main steps, including the segmentation of super pixel and classification machines accordingly. We often use meanshift or watershed methods to get super pixels, and apply (Support  Vector Machine)SVM or (Back  Propagation  Network)BP  toclassification. Nowadays new methods such as (Markov Random Filed)MRF or (Conditional Random Field)CRF are introduced to improve the accuracy by taking nearby super pixel labels into account.\n",
    "First, tradition classifiers such as SVM, BP, logistic classifier are designed to process 1-D signals instead of image.in order to improve the primary accuracy of classification, we introduce the (Fully Convolutional Network) FCN8 network which has the best performance in FCN series, and it can also conduct feature extraction, and meanwhile FCN directly compute on every single pixel instead of pixel group.\n",
    "Next, we introduce fully connected CRF in Deeplab to combine the self label probability with other pixel label around it as prior probability, and use grid optimization method to adjust the proper parameter. FCN has bad performance on edge area due to deconvolution step and convolutional kernel size. we can improve the classification result of edge area by (Domain Transform)DT network, but it has little effect. DT network has many critical problems, I analyze and solve the problems and propose a improved DT diffusion model. By generating edge map through (Holistic-nested Edge Detection)FCN-HED network ,and combine the edge with the output of Deeplab ,also with the output of edge network inside the DT can finally get a better result on accuracy and edge distribution, with the method we call as improved DT 4-D diffusion method and hole filling and inner fusion to get a explicit modification of classification.\n",
    "Last, we do lots of contrastive experiments on ESAR data, such as standard CRF based on pons or SVM classifier with meanshift to segmentation, FCN8, Deeplab and Deeplab-DT, and finally the experiment combining FCN-HED edge network with Deeplab-DT to explicit modification of edge classification effect. through the whole experiment we can conclude that the final experiment has the best performance on total classification accuracy and especially the improvement of edge area about both distribution and classification.\n",
    "\n",
    "**Key words**: Synthetic Aperture Radar, CRF, Fully Convolutional Netwark, explicit edge modification, improved DT model\n",
    "\n",
    "**缩写表**\n",
    "\n",
    "|缩写|含义|\n",
    "|--|--|\n",
    "|SAR|   Synthetic Aperture Radar|\n",
    "|SVM|   Support Vector Machine|\n",
    "|CNN|   Convolutional Neural Network|\n",
    "|FCN|   Fully Convolutional Network|\n",
    "|DT|   Domain Transform|\n",
    "|HED|   Holistic-nested Edge Detection|\n",
    "|CRF|   Conditional Random Field|\n",
    "|MRF|   Markov Random Filed|\n",
    "|BP|   Back Propagation Network|\n",
    "|RNN|   Recursive Neural Network|\n",
    "|LSTN|   Long Short Term Network|\n",
    "|NN|   Neural Network|\n",
    "|R-CNN|   egions with CNN features|\n",
    "|Fast R-CNN|   Fast Regions with CNN features|\n",
    "|Faster R-CNN|   Faster Regions with CNN features|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  绪论 \n",
    "\n",
    "图像处理是指基于图像的基本颜色特征，区域特征，结构特征，纹理特征等 \n",
    "一系列像素点的集合来进行图像的各种处理，包括滤波，去噪，变换等基本操作， \n",
    "化及更抽象的图像识别任务，包括图像分割，图像目标检测，图像分类，其中模 \n",
    "拟人的思维去实现图像的理解是目前主流课题，时下基于神经网络的方法在图像 \n",
    "识别与理解的多个领域有着不俗的成绩，比传统机器学习如SVM， CRF的方法 \n",
    "更有优势。\n",
    "\n",
    "SAR图像的区域分割是指将同属于某种潜在目标或同一类别的某种具体特 \n",
    "征类似的像素点或图元归于一种类别，属性如颜色强度，边缘，上下文等特征， \n",
    "将特征向量相似度高的标记成一种颜色，这样不种属性的区域或物体会分成不同 \n",
    "类别标注，可广泛用于军事的地形分析，民用的粮食产量分析等区域结构的信息 \n",
    "分类。本文基于ESAR卫星得到的多通道伪彩图像，可视作传统光学图像，利用 \n",
    "神经网络的方法以及边缘融合的思路得到更好的分割效果和边缘分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAR图像分类简介\n",
    "\n",
    "SAR (Synthetic Aperture Radar)专门用于对地面进行探测波信号的发射和 \n",
    "回波信号的收集，作为飞机或卫星搭载的雷达装置，可以得到高解析度的多通道 \n",
    "影像，SAR图像通常包含多种散射信息[1]，依据发射和接收信号的方式可分 \n",
    "为单极化，双极化以及多极化的多种方式，SAR对于光学图像的优点是穿透性 \n",
    "强，具有相位信息，多极化与结构信息等，一般来说，SAR接收的回波信号是 \n",
    "复数形式，其中相位代表传播往返途中的时间差，而幅度与物体的光学特性和自 \n",
    "身结构，表面的光滑程度有关。SAR系统广泛的应用在军事和民用上，如军事 \n",
    "基地检测，军队动向，地形探测，植被环境评测，城市规划，自然灾害评估，矿 \n",
    "物资源分析，地球生态等。\n",
    "\n",
    "在1978年美国NASA将SEASAT-1卫星这入地球轨道，这是SAR雷达的 \n",
    "首次实际使用，之后各国陆续发射了各自的SAR卫星或者机载SAR系统，如 \n",
    "ESAR， TerraSAR-X， EMISAR 以及 COSMOSkyMed[2]等等。我国在 SAR 雷达 \n",
    "方面也有很大的发展，1979年我国的中科院的电子研究所率先研制出了机用 \n",
    "SAR雷达的实验工程机，并得到了比较好的效果，但同国外有一定差距而且实 \n",
    "用化不强，到了 2004年中电38所成功在飞机上装载了新型的多极化方式SAR \n",
    "雷达，在试飞过程中接收到了反波信号并得到了较好的SAR多极化的数据，近 \n",
    "年来我国的SAR技术又有长足进展，特别是在2006年我国的第一个卫星搭载的 \n",
    "SAR雷达成功发射，之后的各种相关科研实验也成功进行。\n",
    "\n",
    "SAR图像以物体的后向散射属性为成像机理，还受到物体形状，极化的方 \n",
    "式，入射角度等影响，清晰度也低于传统光学图像。对于不同颜色的物体，需要 \n",
    "多极化方式映射分量到各个通道上合成伪彩图如ESAR数据的Pauli分解伪彩图， \n",
    "但在颜色特征上仍有欠缺。故直接使用传统光学图像的处理方法可能得不到比较 \n",
    "好的结果，但随着SAR图像的清晰度越来越高，伪彩图的质量越来越符合光学 \n",
    "图像的特性，一些现在比较流行的光学图像方法如神经网络，CRF等也在运用 \n",
    "于SAR图像的处理上。\n",
    "\n",
    "SAR图像分割是SAR图像处理的最重要的应用，通过将拥有相近属性的相 \n",
    "连区域融合成一块，以在图像上形成多个区块，通过不同颜色标记，得到区域的 \n",
    "分割图，如划分成田地，水域，建筑区，道路等，之后便可进行相关的军事或民 \n",
    "事应用，主要的分割方法如传统的无监督聚类分析，及基于像素点或像素块的 \n",
    "特征提取加分类器的监督方法，通过应用不同的产生或判别模型，应用样本来训 \n",
    "练参数以最低化拟合误差，最终得到分类结果，运用到的特征包括颜色，强度特 \n",
    "征，极化或散色特征，纹理特征等。利用SAR伪彩图可以将最新的神经网络技 \n",
    "术应用到SAR分割上，直接利用颜色信息，与传统的光学图像并无方法上的区 \n",
    "别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAR图像分类的发展现状\n",
    "\n",
    "不管对于传统光学还是SAR图像信号，都属于二维多通道信号，故都有监 \n",
    "督与非监督的方法。监督的效果比非监督好，非监督的比较方便。早期的SAR \n",
    "非监督方法主要运用到SAR的后向散射原理，利用SAR特性相关的特征[3]。1989 \n",
    "年，VanZyl[4]为了解决地面的城市内部不同区域的标注问题，通过仔细研究各区 \n",
    "域的空间结构发现每种物体的空间结构可根据散射特性分为四类，然后利用散 \n",
    "射矩阵分解实现了非监督的分类方法。1997年，Cloude等人[5]根据散射矩阵的 \n",
    "特性得到了 H/alphalpha分解[6]算法，其后根据分解后的结果利用非监督算法聚类得到不 \n",
    "同类别的像素点颜色标注。我们知道SAR图像存在很多噪声干扰，为了降低噪\n",
    "声所带来的误差，在传统的分类方法中又考虑了空间相近度[7]和上下文背景信息[8]\n",
    "，这样会减少噪声信号的影响权重，提高正确率。\n",
    "\n",
    "对于原始的SAR信号，可以直接应用散射系数数据，也可以生成相干矩阵 \n",
    "和协方差矩阵，早期的方法使用多极化或多波段的信号组合。对于极化数据，其 \n",
    "包含的信息除了后向散射的强度外还有相位信息，对应于每个像素点都可提取 \n",
    "相关的特征向量，通过样本标签训练相应的分类器如SVM[24][25]，朴素贝叶斯[20] \n",
    "极大似然[9]，BP[10]等，直接利用对应点特征向量的方式是早期的主流思路。 \n",
    "在20世纪70年代后，为了解决SAR图像分割任务，人们开始尝试使用多种 \n",
    "的不同极化条件下目标分解方法，主要是根据SAR信号特性将其映射到多个不 \n",
    "同的分量上，针对不同的目标和处理的目的，可以有多种分解方式，不存在绝对 \n",
    "的万能方法，不过依据此原理人们得到了比较好的解构雷达的后向散射数据的方 \n",
    "法。目标分解主要有两种方法，包括相干分解与非相干分解。一般来说，相干分 \n",
    "解对应于全极化房向散射波，它的散射矩阵包含完整的全极化散射信息，不过实 \n",
    "际散射波几乎是部分极化的，所般用非相干分解将原始散射矩阵表示为单矩 \n",
    "阵分量之和，这为在SAR数据中提取实际地理数据和物体分布与色度起到至关重 \n",
    "要的作用，是一个简单有效的方法[11]。在1970年初，huynen[12]开创性的考虑到 \n",
    "SAR的散射持性，将其具体的反射情况分成多种，这样可以将得到的矩阵信号 \n",
    "映射到多种反射情况上，得到不同的矩阵分解信息。1986年后，Cloude利用Pauli \n",
    "分解的方法，结果可以将地面物体映射到四个不同的分量上，成功的提取到 \n",
    "具体物体结构关键信息。1990年初Krogager改进了原有的分解方法[14]，由不同 \n",
    "的角度将分解映射到三个不同的结构特征分量上。1997年，Cloude得到了 H/alpha \n",
    "的矩阵映射方法使得分解效果有进一步提升，1998年后，一批着手于将原矩阵 \n",
    "进行依照空间结构的分解映射的算法涌现，如98年的freeman[15]得出的一种新 \n",
    "的映射方法，仍然是映射到三种分量结构上，不过具体规则有所改变。2005年 \n",
    "Yamaguchi[16]首次将四分量的分解思路运用在散射矩阵的分解上，这样提出的关 \n",
    "键信息更为完善。2007年，Touzi利用散射特征矩阵提取旋转不变的分量，这是 \n",
    "－种典型的非相干分解[17]方法，2012年一些三分量[18]和依靠具体扩展结构而做 \n",
    "不同处理的四分量映射方法被提出[19]。结合不同的目标分解方法，己成功用于 \n",
    "SAR图像分类的分类器包括贝叶斯抉择[20]、Wishart最大似然估计[21]、马尔科夫 \n",
    "随机场(Markov Random Field， MRF)[22][23]、支持向量机(Support Vector Machines，SVM)[24][25]、条件随机场(Conditional Random field， CRF)[26][27][28]等。\n",
    "\n",
    "上面的方法都是利用SAR信号基于物体实际的几何特征或后向散射形成的 \n",
    "散射矩阵的多种多分量模型分解算法，实际上传统图像信号所用到的特征属性如 \n",
    "纹理特征对SAR雷达信号得到的伪彩图提取也具有极好的效果，典型的如灰度 \n",
    "共生矩阵[29][30]，纹理小波分析[31]和离散小波变换[32]、半方差图[33]  2011年，dai[34]\n",
    "通过引入多层次多尺度的直方图特征来描述纹理，对于全局信息和区域局部信息 \n",
    "都有反映，比较传统方法性能得到了很大提升。不仅如此，多种特征组合使用也 \n",
    "是一种新的思路，不管是多种散射矩阵的分解向量组合还是利用传统特征的如灰 \n",
    "度共生矩阵或harr特征，将他们串联成高纬度的特征向量形式[35]，后经过分类 \n",
    "器如决策树算法，SVM分类器等进行地面的物体分类，在如RADARSAT-2等 \n",
    "SAR图像上有成功应用, 当时基于极化散射的时间序列用于人工目标分类[36]和应 \n",
    "用特征包(Bag-of-features)和金字塔表征的SAR数据分类[37]也一直是SAR图 \n",
    "像分类研究中的热点方向。\n",
    "\n",
    "传统的SAR图像多是利用原信号的多个后向散射通道直接提取特征，其代 \n",
    "表的颜色信息常常不为人知，近年来由于在传统光学图像上分割算法特别是神经 \n",
    "网路的成功使得人们开始在极化SAR上寻找颜色信息，具体做法是将目标散射 \n",
    "矩阵分解到RGB 三个通道上，如基于H/V极化矩阵的Pauli分解形成的伪彩图。 \n",
    "这几年很多更好的SAR图像显示手法被利用到，比如deng[38]根据实际的SAR \n",
    "散射特性，给出了对应的可视化思路，而turner[39]利用椭圆极化坐标重建SAR图 \n",
    "像，较好的利用到了极化特性与传统空间上下文的关系。Uhlmann等组合利用多 \n",
    "个可视化的颜色特征描述元作为特征来进行监督分类的训练与学习。基于颜色的 \n",
    "特征组合方法与传统纹理的方法对比有较好的效果，将两者组合起来能进一步提 \n",
    "高分割正确率。\n",
    "\n",
    "不管对于传统光学光学图像或是SAR图像，单纯用像素点信息提取特征会 \n",
    "导致巨大的噪声干扰，主要会出现同种类别差异很大或者不同类别差异变小的问 \n",
    "题，因此判断某像素位置的类别时可以引入周围像素对该像素的影响综合判断， \n",
    "因此上下文相关分类对SAR图像解译有着举足轻重的作用。最基础的如MRF \n",
    "模型，利用最小化全局优化函数，该函数考虑到像素周围点的综合影响。Elia[22] \n",
    "利用将图像分成多个区域后，对每个区域提取形状无关的特征纹理向量，作为 \n",
    "MRF的输入特征，进而对区域分类，Voisin针对区域处理上缺芝细节错误问题\n",
    "以及上级层面的约束，故引入了多层次的约束影响关系，高层次对低层次有类别 \n",
    "的先验影响，Tison[40]利用MRF在实际SAR图像分割上取得了较好的结果。MRF \n",
    "属于产生式模型，而通常对于样本的联合分布建模是非常困难的和不精确的[41]， \n",
    "故CRF被提出用来专门针对信号的分类任务，CRF是判别式模型，主要考虑给 \n",
    "定样本后标签的概率分布来取得最大的后验概率结果。Su最早将CRF的方法引 \n",
    "入SAR相关信号或图像的分割，Zhang进一步考虑到了边缘类别先验概率的影 \n",
    "响，然后将其置入CRF的成对势函数中作为先验项，Ding[42]通过设计选择不同 \n",
    "的单元势函数和成对势函数，确定较好的模型设置和函数设置以使得具体结果的 \n",
    "各项评价指标得到改善。近年来，神经网络的出现特别是CNN等专门针对图像 \n",
    "信号或多通道二维信号的深度学习架构在图像分类与分割上取得了惊人的结果， \n",
    "通过将FCN直接用于SAR伪彩色图像进行分类也取得了较好的结果，一些人将 \n",
    "CRF作为后置处理接在FCN的后面改善了图像分割的轮廓和正确率，由于神经 \n",
    "网络的便捷性，我们可根据训练样本来训练相关的模型，用FCN等一系列网 \n",
    "络来处理分割问题是目前的主流方向。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络简介\n",
    "\n",
    "神经网络的发展归因于人类对大脑的初步认识，人们发现每个神经元都可以 \n",
    "归结于相似的数学方程来表示，他们可以有多个输入或输出节点，神经元突触连 \n",
    "接着每个神经元，连接的强度会依照学习或记忆过程而发生变化。神经网络典型 \n",
    "的架构是多层次结构，最基础的必须要有输入与输出，中间会有很多的间接层， \n",
    "内部结构执行的运算一般是矩阵运算和激活函数，当然只要能进行求导的运算都 \n",
    "能被引入进去，具体需要根据网络要实现的目标和功能来决定，当给定训练样本 \n",
    "时，可按照最小化方差的误差函数按照梯度下降原理给出反向传播算法，通过 \n",
    "多次迭代更新神经元的连接权值，更新的目的是让神经网络自适应调整自己的参 \n",
    "数来适应样本使得拟合的误差最小。一般来说，人的脑神经元是需要激活的，当 \n",
    "输入达到某一临界值才会使得后续的神经元开始工作，故很早之前的激活函数是 \n",
    "一种阶跃函数，但在具体使用时发现严格依照激活的原理对实际应用有很大限制， \n",
    "所以现在对激活函数的使用更加广泛，早期的激活函数是线性函数，显然这样的 \n",
    "映射关系无法解决非线性的问题，通过引入如Sigmoid等非线性的数学关系， \n",
    "Sigmoid的任何输入都会被非线性的映射到0到1之间的实值，这样对于解决异 \n",
    "或等复杂的问题有极大帮助，对于之后的任意拟合的能力提供了数学基础。 \n",
    "神经网络是神经元按层次巧组合连接形成的具有深度和层次连接的网络结 \n",
    "构，对应于不同的分类任务会对应于不同的连接权值，这主要取决于工程师选择 \n",
    "的训练测试样本和对应类别标注文件。虽然只是简单模拟人脑构造，但实际应用 \n",
    "中发挥了令人惊喜的作用，不管在一维信号或图像的分类中取得了骄人的成绩， \n",
    "就连特征提取的过程也可被训练，实践证明训练得到的特征提取器比人工选择 \n",
    "的特征更为精确，更能反映信号本质。\n",
    "\n",
    "1943年左右，M-P模型被数学家皮兹和心理学家麦克洛奇提出，该模型认 \n",
    "为每个神经元都可以看作一个逻辑功能元件，多个逻辑元件组成神经网络。1949 \n",
    "年hebb创造性的认为神经细胞之间的突触的连接权重能够适应性的不断改变以 \n",
    "应对新的目标，不管对于学习还是记忆，突触的连接强度反映了学习与记忆的过 \n",
    "程。第一代神经网络的出现在1957年，其基本原理是单层感知器模型，该模型 \n",
    "除了输入层和输出层外还有一层隐含层，层之间的节点没有连接，层与层之间的 \n",
    "节点都有连接，神经元突触权重可变，输出层后接一个激活函数使得到的值为1， \n",
    "-1或1，0，感知器的缺陷显而易见，输出只有两个值不利于多分类，没有适合 \n",
    "多层感知器的训练算法。1959年，美国工程师威德罗化(B.Widrow)和霍夫(M.Hoff) \n",
    "提出了自适应线性元件(Adaptive linear elemment，简称Adaline)和Widrow-hoff学习规则。 \n",
    "1969年，明斯基在其《感知器》一书中证明了线性感知器无论组合成多少 \n",
    "层都无法解决非线性分类问题，比如最简单的异或计算，神经网络的研究陷入了 \n",
    "黑暗时期。在此期间，1972年SOM网络被芬兰的KohonenT.教授提出，该模型 \n",
    "采用无监督机制，采取竞争的机制，胜者为王，与聚类分析的算法同巧于无监督 \n",
    "分类。\n",
    "\n",
    "1982年Hopfield模型出现，之后hinton将它的激活函数由离散型转变成连 \n",
    "续型并成功解决了著名的旅行经销商问题，1984年hinton与年轻学者Sejnowski \n",
    "等合作提出了玻尔兹曼机，主要依照模巧退火算法的思想。 \n",
    "1980年代，误差反向传播算法被儒默哈特提出，第二代神经网络形成，一 \n",
    "系列多层次的BP网络开始应用于实际问题，除了BP算法可以适应多层网络的 \n",
    "训练外，感知器的激活函数也变成了Sigmoid等非线性映射函数，有效解决了非 \n",
    "线性分类问题。同时期还有RBf和反馈神经网终，如Elman，hopfield等都具有\n",
    "RNN结构的特征，RNN是重要的循环神经网络的简称，适合处理序列信号和关 \n",
    "联信号。1986年，并行分布式处理理论证明了 BP算法的有效性以及对非线性问 \n",
    "题的适应能为。\n",
    "\n",
    "2006年后深度学习的概念被hinton提出，一系列基于深度学习的网络架构 \n",
    "形成，通过组合与加深各种功能层实现不同的图像识别或检测的任务，其中最重 \n",
    "要的的基石便是CNN。\n",
    "\n",
    "卷积神经网络(CNN) [43]主要是得益于动物视觉成像原理的研究，其中最 \n",
    "重要的是感受野的原理，在1990年代，lecun为了解决银行提出的手写数字自动 \n",
    "判断与分类的问题设计了 lenet网络并有着极高的精准度，第三代网络出现，但 \n",
    "是之后面对更大规模的图像问题该网络表现的并不好，直到2006年 \n",
    "Krizhevskyetal设计了著名的AlexNet架构，成功的解决了一些复杂的图像分类 \n",
    "问题，通过不断加深CNN的结构，ZFNet[44]，VGGNet[45]，GoogleNet[46]和 ResnNet[47] \n",
    "等一批新的神经网络架构出现，使得目前的分类效果化及其他的一些应用得到了 \n",
    "较好的提升和改进。\n",
    "\n",
    "神经网络具有人类大脑的核心特性，通过模巧大脑神经系统的运作原理，与 \n",
    "传统的机器学习方法有本质的不同，使其在大部分问题的解决上有着不可取代的 \n",
    "优势。第一，具有计算并行性，网络层之间是串行的，但单个网络层之中的神经 \n",
    "元(特殊设计的网络例外)没有直接连接，相互没有依存关系，他们进行的计算 \n",
    "可以并行存在，实际的GPU中计算也是将单层神经元的计算映射到每个计算单 \n",
    "元上，通过GPU并行计算提高速度，人脑中突触间信号的传递速度远低于我们 \n",
    "现在使用的计算机频率，之所以在抽象任务的判断上人脑远优于电脑，甚至有着 \n",
    "电脑无法解决的问题，其中一个重要方面是大脑的信号处理高度并行性，一个任 \n",
    "务会被分解为多个神经信号通道同时计算最终合成结果。第二，非线性与全局性， \n",
    "不管激活函数是Sigmoid函数还是Sign函数都无法写作线性关系式，非线性的引 \n",
    "入解决了非线性分类问题，为逻辑学运算打下了基拙，为非线性拟合问题找到了 \n",
    "解决思路，全局性是指每层的神经元接受上层所有神经元的输入，每个输入神经 \n",
    "元对最终结果都有影响，单看单个神经元没有任何价值，只有所有神经元共同合 \n",
    "作才能正确实现分类目的。第三，强大的容错性，单个神经元突变或少数权重的 \n",
    "更迭不会影响最终的分类结果，因为所有神经元都参与了计算结果，神经元之间 \n",
    "也有大量的有权重的联系，就像人类的大脑一样，损失一些脑细胞并不会对整体\n",
    "的思维能力产生负面的影响。第四，适应性与学习性，对于同一个网络，采用不 \n",
    "同的训练样本就可以训练得到不同的权重网络，这说明该网络对问题的解决具有 \n",
    "普适性，功能的不同仅仅只是权重上的差异。除此之外，该网路具有人的抽象识 \n",
    "别能力，比如将狗的样本和非狗的样本标注后放到CNN网络进行训练，可以得 \n",
    "到一种分辨是否为狗的网络模型，此时放进一张新的不同品种或体型的狗，该网 \n",
    "络仍能有效识别是否为狗，哪怕是新的完全不认识的图片。如果此时需要判别狗 \n",
    "的品种，那么可标注不同的狗的类别标签，进一步训练该网络就可以得到新的 \n",
    "能分辨狗的类别的模型，而不用改变原有的结构与神经元分布。第五，非凸性， \n",
    "此性质表明该网络具有极值，可以进入到某个稳定的系统状态，则可用梯度下降 \n",
    "法解决该非凸问题，又由于网络的层次结构，故提出了误差反向传播法来简化计 \n",
    "算，优化梯度更新过程。第六，分布式存储方式，权重处在网络所有的连接中， \n",
    "问题的解决需要所有权重的参与，各层各个神经元之间有着紧密联系，类似于人 \n",
    "类的联想记忆功能。\n",
    "\n",
    "对于在实际的运用过程中，神经网络对比其他方式具有显著的人工智能特点。 \n",
    "第一，分类与识别功能，对于信号之间的对比与抽象能力，以及特征之间的分类 \n",
    "与识别，神经网络具有人类的高度抽象化辨别能力。第二，联想记忆能力，所有 \n",
    "的神经元都负责一部分的计算，具有并行计算与集体智能的行为，对于图像的整 \n",
    "体理解有着重要的应用。第三，快速拟合功能，针对未知或己知的目标函数，或 \n",
    "者满足训练样本的分布，能通过梯度下降法快速得到稳定状态。第四，任意映射 \n",
    "能力，由于激活函数的引入，以及神经网络的层次化和数量的庞大，使得该网络 \n",
    "可以逼近任意函数，使其成为了通用的函数拟合模型。\n",
    "\n",
    "CNN主要针对图像信号的整体分类，主要负责图像分类的任务，2012年后， \n",
    "适合其他任务的各种改进网络开始出现，针对图像的语义分割任务基于 \n",
    "VGGNet提出了 FCN， deeplab， CRFASRNN[48]等一系列方法，对于图像检测 \n",
    "这块又有RCNN[49]，fastRCNN[50]，fasterRCNN[51]以及YOLO[52]等用于目标检测， \n",
    "对于文本处理有RNN，LSTM等序列信号分类方法，最后对于最新的实例分割 \n",
    "有DEEPMASK等方法，对于边缘检测或模糊去除等目的也有一些FCN为基 \n",
    "础的改进网络。 \n",
    "\n",
    "|目的|   神经网络的方法|\n",
    "|--|--|\n",
    "|图像分类|   CNN(VGGNET,ResNet,GOOGLENET,ZF)|\n",
    "|图像语义分割|   FCN(FCNB),Deeplab,CRFASRNN|\n",
    "|图像实例分割|   DEEPMASK|\n",
    "|文本语音分类|   BP,RNN,LSTM|\n",
    "|图像目标检测|   RCNN,fast RCNN,faster RCNN,YOLO |\n",
    "|图像边缘检测|   FCN-HED|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本文的研究内容和方法\n",
    "\n",
    "经典的传统方法要进行超像素块的分割，块特征的提取，以及特征分类器这 \n",
    "三个步骤，meanshift或分水岭方法常用于超像素块的提取，分类器多采用SVM \n",
    "或BP等，之后也引入了 MRF和CRF进一步考虑周围超像素块的分类类别从而 \n",
    "进一步提高了正确率。\n",
    "\n",
    "首先，以前的方法的分类器多使用传统如SVM， BP，logistic等分类器， \n",
    "这些分类器并不适合图像信号，为提高图像巧始的分类正确率，引入FCN中效 \n",
    "果最好的FCN8作为分类器，FCN8同时也负责卷积特征提取，同时FCN不需 \n",
    "要先用一些meanshift或者分水岭算法来将图像转变成多个区域的形式，而是直 \n",
    "接作用于每个图像上的像素点。\n",
    "\n",
    "然后，为了考虑周围像素分类类别的影响，同时考虑自身像素的分类类别， \n",
    "引入deeplab的全连接CRF综合考虑周围像素的类别先验信息，并用网格优化 \n",
    "法得到合适的CRF相关参数。\n",
    "\n",
    "FCN网络用于分割时边缘部分的像素点分类不准确，这是反卷积和卷积的 \n",
    "卷积核尺度决定的，在deeplab内部利用DT网络可以稍微修正边缘像素点的分 \n",
    "类结果，但效果不显著，在deeplab外部利用FCN边缘网络提取边缘信息，分 \n",
    "别与DT的内部边缘网络输出融合后输入DT中，然后与deeplab的结果进行后 \n",
    "置融合，融合方法包括我提出的扩散法和补洞法。同时在内部和外部进行边缘融 \n",
    "合最终可将分类结果边缘改善以及提高一定的正确率。\n",
    "\n",
    "最后在ESAR数据上进行了多方案的对比实验，分别为基于potts先验的标 \n",
    "准CRF或SVM分类模型并采取meanshift分割的方法，FCN8， deeplab 以及 \n",
    "deeplab-DT和最终的deeplab-DT加FCN边缘网络融合的方法，实验表明每一 \n",
    "种方案都比较以前的方案有一定提升，最终的边缘后置融合的方案效果最好，正 \n",
    "确率最高同时边缘修正的效果很好。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 论文的结构安排\n",
    "\n",
    "第一章绪论，祥细讨论了 SAR图像信号的产生机制以及诸多特点，强调了 \n",
    "SAR图像分割的目的和应用，又介绍了一些传统的分割算法化及最近的一些发 \n",
    "展和理论，之后着重介绍神经网络的特点和历史，进一步介绍其用于图像信号的 \n",
    "CNN网络和其各种变种和发展。\n",
    "\n",
    "第二章详解CNN和FCN网络，对FCN的计算过程和细节完整揭示，并分 \n",
    "析FCN网络的特点和FCN8的优点和FCN网络的一些通病。\n",
    "\n",
    "第三章详解deeplab和DT网络，将fullyCRF引入后置，这样在分类时可 \n",
    "以同时考虑周围像素点的分类结果和自身的分类结果，得到较好的平衡。DT网 \n",
    "络可以进一步修正边缘分类效果，使边缘平滑。\n",
    "\n",
    "第四章引入FCN边缘网络显式的得到边缘和边缘距离图，分别与DT的內 \n",
    "部边缘网络输出融合后输入DT中，并用改进的扩散法与补洞法进行分割结果与 \n",
    "边缘的后置融合，最后得到整体的模型，实际结果有进一步提升，边缘修正使得 \n",
    "整体正确率提升。\n",
    "\n",
    "第五章实现所有方案的实验，并得到所有的相关结果，对结果进行分析，评 \n",
    "价现有方案和改进方案的优劣，及展示改进的效果和整体正确率的提高。\n",
    "\n",
    "第六章综合归纳之前的实验结果和各种方案的优劣，并提出下一步适当的改 \n",
    "进方案和其他方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于标准FCN神经网络的分割模型\n",
    "\n",
    "## CNN卷积神经网络\n",
    "\n",
    "### CNN基本原理\n",
    "\n",
    "CNN的前身源于对动物视觉的成像原理的研究，通过模拟感受野机制和视 \n",
    "觉处理过程的层次化结构特性，一些有着CNN原始架构的网络开始出现并用来 \n",
    "处理简单的分类问题。不过2006年后，随着硬件特别是GPU的发展，可以解决 \n",
    "复杂图像分类的CNN深度扩展网络开始流行并且多种网络结构陆续出现。\n",
    "\n",
    "对于传统的一维信号，BP网络一般采取全连接的形式，对于数量级不是太 \n",
    "大的一维向量，运算时间在接受范围以内。而对于二维信号，典型的如图像信号， \n",
    "如果简单将其拉伸到一维向量，不仅尺度过大，而且这种处理方式丢失了图像的 \n",
    "结构信息和空间信息。CNN就是专门为处理图像而设计的一种神经网络，其核 \n",
    "也就是感受野的应用，通过限定某尺度的卷积核在图像上滑动，类似于图像的滤 \n",
    "波操作，以此来提取图像的显著惟特征。\n",
    "\n",
    "对于传统的图像处理，特征一般人为设定，该特征不一定最能反映信号的本 \n",
    "质区分，而卷积核的参数是根据样本来训练得到的，为达到最优化匹配，其得到 \n",
    "的卷积特征必定最能反映图像的特点，事实上，通过对图像分类任务的CNN隐 \n",
    "含层的可视化发现，**卷积核提取的一般是高频信息**，反映了边缘和角点信息。 \n",
    "CNN卷积核的结构使其具备平移不变性，对适度的形变扭曲和方向改变有 \n",
    "着适应性，卷积核有多个，CNN的每个通道的二维特征图都对应于多个卷积结 \n",
    "果的叠加，对应于每个输出通道的卷积核的个数与输入图像的通道数一致。尺度 \n",
    "上CNN的卷积层可以表示为n＊c＊h＊w， n是批处理图像个数，c为通道数，w和 \n",
    "h分别为宽和高。如果输入的图像通道数为cl，输出图像的通道数为c2，则所 \n",
    "需卷积核数为cl＊c2。当然，CNN除了卷积层还有两个重要的层，一个是RELU \n",
    "层，通过可导的非线性映射函数将值映射到0到1之闻，不仅可以限制值大小减 \n",
    "少达到平衡状态的迭代次数，还可以引入非线性解决非线性分类问题。另一个是 \n",
    "pooling层，通过等比例减小特征图尺度降低计算难度和提取关键信息。 \n",
    "CNN的另一个特点是层次性，类似于人的视觉系统，层次结构由底层到高 \n",
    "层，一般越往深层次其得到的特征图尺寸越小，而其抽象程度越高，得到的特征 \n",
    "更能反映图像信号的本质区分，这样的特征通过全连接层映射到一维向量后可降 \n",
    "低信号维度和减少结构信息的影响，最后接上softmax多分类层即可输出对应的 \n",
    "类别(取概率最大的节点为其类别)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN基本结构\n",
    "\n",
    "一批基于CNN原理的网络结构如Vgg，GOOGLE， ALEX都得到了很好的 \n",
    "应用，CNN架构也不再仅限于图像分类任务，对于图像分割和图像检测，分别 \n",
    "有基于CNN的如FCN和RCNN用于实现。目前来说，基于CNN的扩展深度和 \n",
    "层次结构的各种定制网络仍然是目前的处理图像信号的主流思路。 \n",
    "CNN的基本层结构如下： \n",
    "1，卷积层 \n",
    "卷积层的操作类似于图像滤波，通过可设定大小的卷积核在图像上沿着行与 \n",
    "列扫描得到滤波后图像，当然还必须加上与滤波后图像维度相同的偏移量矩阵， \n",
    "这就是卷积层的基本功能，用于图像的线性滤波和卷积特征提取。在卷积层中， \n",
    "如式(2.1)，假设i为输入图像的通道数，j为输出图像的通道数，l为层次数， \n",
    "知为对应于输入图像第i个通道的第j个卷积核，$b_j$表示输出图像第j个通道的 \n",
    "偏置，乘号表示卷积操作，f 一般不取任何操作，由之后的RELU层来产生非线 \n",
    "性映射。 \n",
    "$$\n",
    "(2.1)\n",
    "\\ x_j^l = f(\\sum_{i \\in Mj}^{} x_j^{l-1}*k_j^l + b_j^l)\n",
    "$$\n",
    "\n",
    "2，池化层 \n",
    "对图像做下采样如2＊2，4＊4等的比例放缩，按照放缩后的取值规则可以有 \n",
    "maxpooling即极大值采样，avgpooling即平均采样，randpooling随机采样等， \n",
    "pooling的作用主要是在不影响主要特征提取保留显著特征的情况下降低图像维 \n",
    "度。在pooling层中，如式(2.2)，输入通道数与输出通道数一样都为j，一般来 \n",
    "说在实际应用中，down表示下采样，$beta$统一取1，b都为0， f不取任何函数， \n",
    "只是让pooling层完成降维操作。pooling层的作用除了降维以外，还可使该区 \n",
    "域特征满足旋转不变性。对于pooling层的误差反传，假设采取最大值pooling， \n",
    "一般要记住池化前每个单元最大值所在位置，这样反传时除了尺度扩大外，原来 \n",
    "的保留位畳对应各自的误差值，其他位置值为0。 \n",
    "$$(2.2)\n",
    "$$\n",
    "3，RELU 层 \n",
    "原始的RELU函数是MAX (0，X)，计算简单没有上限，更进一步将输入值 \n",
    "通过Sigmoid函数$g(z) = 1 / (1+\\exp(-z))$将负无穷到正无穷的范围映射到0到1的 \n",
    "范围，除了起到约束数值范围加快收敛外，更重要的是引进了非线性关系，有利 \n",
    "于解决非线性分类问题。 \n",
    "4，全连接层 \n",
    "通过将二维图像信号按从左到右，从上到下的顺序连接成一维向量并类似 \n",
    "BP网络层间结构映射到另外一个长度较短的一维向量层。如果不接后面的 \n",
    "softmax层，那么代价函数一般取方差和函数，如式(2.3)，其中n为样本的个 \n",
    "数，E为目标误差，c为输出节点数，t为真实样本标签，y为网络得到的类别值， \n",
    "一般其他类别的真实值取0或-1，样本标签对应的输出节点值取1。 \n",
    "$$(2.3)\n",
    "E^N = 0.5 \\sum_{n=1}^{N}\\sum_{k=1}^{c}(t_k^n - y_k^n)^2\n",
    "$$\n",
    "5，softmax层\n",
    "设定softmax层输出节点数量为待分类类别数量，输入为全连接层的输出， \n",
    "通过softmax函数得到每个输出节点的概率分布，最大的概率对应的节点即为所 \n",
    "得到的类别。如式(2.4)，假设类别y可以取k种类别，即有k个输出节点，$\\theta$\n",
    "为模型矩阵参数，累加项为归一化参数使输出节点概率之和为1。如果输入x有 \n",
    "n个节点，则实际输入会在x向量后补1 以引入偏置项，这样$\\theta$的尺度就变为 k＊(n+l)。 \n",
    "$$(2.4)\n",
    "$$\n",
    "对于目标代价函数，一般不采用神经网络通用的最小方差和的思路，而是采 \n",
    "取最大似然的方法，如式(2.5)，1{}表示真值判别式，根据括号里的表达式输 \n",
    "出1或0， m表示输入数据的个数，J代表损失函数，j代表类别标号。 \n",
    "$$(2.5)\n",
    "$$\n",
    "对于该代价函数一般采取梯度下降法来求得梯度，如式(2.6)通过迭代更 \n",
    "新的方式来进行优化，m为样本数，y为类别标签，x为输入向量。\n",
    "$$(2.6)\n",
    "$$\n",
    "通过卷积层和RELU层以及池化层的不同叠加与组合，及其它trick层如 \n",
    "dropout，LRN层等的添加与应用，形成了诸如ZF，VGGNET，googlenet \n",
    "等的现在比较流行的固定结构。 \n",
    "\n",
    "![图2.1 CNN结构图]()\n",
    "图2.1 CNN结构图 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于FCN网络的图像分割\n",
    "\n",
    "### FCN网络的结构\n",
    "\n",
    "CNN适合整体分类，通常输入一张图片得到一个类别标号，如果需要对每 \n",
    "个像素点分类，传统的方法是截取以该点为中心的一个方形区域输入到CNN中 \n",
    "来判断类别，但该方法存在很多问题，首先如果对每个点都采取取框操作，则每 \n",
    "次计算的框的重叠部分都会重复计算从而耗费大量时间，而且该点的类别不会受 \n",
    "到框外的像素点的影响，不具有层次性和全局性。\n",
    "为了解决CNN在像素级分类上的缺陷，Jonathan Long等人通过创新的引入 \n",
    "反卷积层形成FCN[53]网络，并得到毎个像素点的分类结果。我们知道一般的CNN \n",
    "最后会将二维特征矩阵展开成一维向量再进行分类，所以为了得到像素级别分类 \n",
    "的效果，在最后一层二维特征层后面接一个反卷积层，这样通过调节反卷积尺度 \n",
    "可以将该特征图恢复成略大于原图尺度的通道数与类别数一样的特征图，最后需 \n",
    "要crop层切割该特征图，通过该图中屯、为参考取出原图尺寸的特征图即可， \n",
    "最后加一层二维的softmax即可输出类别标注图。 \n",
    "\n",
    "![图2.2 FCN基本结构]()\n",
    "图2.2 FCN基本结构 \n",
    "\n",
    "FCN有5个pooling层，逐层的尺度会除以2来缩减，越往上由于尺度变大 \n",
    "细节信息越显著，而往下的话尺度变小但抽象性变高从而特征图的正确率变高， \n",
    "通过融合不同pooling层的信息，最后一层的反卷积层尺度会有所改变，可以得 \n",
    "到诸如FCN32， FCN16， FCN8等的扩展结构，所以需要在FCN的一些扩展结 \n",
    "构上选择最合适的结构，相关实验证明FCN8是比较合适的结构，下图是这个卷 \n",
    "积和反卷积上采样的过程： \n",
    "\n",
    "![图2.3 FCN系列结构图]()\n",
    "图2.3 FCN系列结构图 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN网络的特点 \n",
    "\n",
    "FCN8总共具有5层pooling，每层的pooling尺度都是2＊2，这样我们就可 \n",
    "M寻到维度为1/2，1/4，1/8，1/16，1/32尺度依次递减的五种特征图，越往下得到的信 \n",
    "息越偏于顶层信息，因为尺度越小的图上的点对应于原图的卷积区域越大，通过 \n",
    "将1/32的层反卷积以升维成1/16再与原1/16叠加可得新的1/16层，之后 \n",
    "再反卷积2＊2升维至1/8与原1/8层叠加得到新的1/8层，最后16＊16高斯平滑核 \n",
    "并以8＊8尺度反卷积恢复到原尺度，此时尺寸可能稍微大于原图，具体的尺度偏 \n",
    "差由Crop层居中切除对比原图多余的尺度，最后接上一个二维softmax层得到 \n",
    "每个点的类别概率分布。\n",
    "\n",
    "FCN32的分类结果过于模糊而不精细，但若模仿FCN8的方法推出FCN2 \n",
    "网络由于参数的增多会出现过拟合现象，反而不如FCN8，经过无数的扩展网络 \n",
    "或者应用场景测试，FCN8的确具有最好的效果，这也是为何后续改进都以FCN8 \n",
    "为基本结构，目前主流方法都会先训练出对应的FCN8模型后再进行微调。从结 \n",
    "构层面上看，FCN8也融合了8倍率，16倍率，32倍率的层次分类信息，本身 \n",
    "就是一种多层次模型。\n",
    "\n",
    "不管扩展结构如何改变，FCN也存在一些问题，即便是FCN8的反卷积也 \n",
    "相当于一个点的信息被映射到64个点上，尺度扩大了8倍，这样的结果是分类 \n",
    "不够细致，特别是边缘远些有跳变的区域，会发现经常出现越过边缘的情形。FCN \n",
    "分类时卷积核一般设定为3，反卷积时也是直接反向映射，没有考虑较远的周围 \n",
    "区域的类别对中也像素点的影响，所以之后需要引入deeplab架构中的后置CRF \n",
    "来优化FCN8的结果。\n",
    "\n",
    "FCN网络的思想不仅仅只是用来做分割的用途，恢复也不一定要还原到原 \n",
    "来的尺度，当样本目标对象为高尺度的原图像放大结果时，那么训练后的网络可 \n",
    "以用来进行高分辨率重建，当目标对象为边缘强度时，那么训练后的网络可以当 \n",
    "做边缘提取器，当样本是抖动后的图像而目标是原图像时，那么该网络就可以用 \n",
    "来去抖动，当然上述网络可能对不同的目杨用途会加以细微的改变，但从根本上 \n",
    "看，该网络只是提供了一种二维空间数据到另外一个尺度的二维空间数据的任意 \n",
    "映射关系，而这种关系是需要被学习出来的，那么具体的用途与原始样本和所应 \n",
    "该得到的训练的目标对象有着密不可分的关系，根据设定不同的样本巧目标，可 \n",
    "以完成现实工程中很多重要的问题和提供适当的解决思路。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章小结\n",
    "\n",
    "本章主要介绍CNN的历史和实际的结构，介绍了一些关键层的功能和种类， \n",
    "以引申出基于CNN的FCN网络，得到像素级分类的神经网络，详细剖析了FCN \n",
    "与CNN的不同之处，以及FCN的各种系列网络的特点，最终得到最适合的FCN8 \n",
    "的网络，并为以后的扩展和改进做铺垫。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于deeplab和内部边缘校正的神经网络的分割模型 \n",
    "\n",
    "## 基于像素块的传统CRF模型 \n",
    "\n",
    "### 传统potts先验CRF \n",
    "\n",
    "受到最大熵模型和MRF的影响[54]，CRF也于近年来被提出用来进行信号分 \n",
    "类。不同于MRF，CRF虽然是基于概率图原理的无向图模型，但MRF是产生 \n",
    "式模型，该模型可以描述所有变量的联合分布，也可以很方便的转化为判别式模 \n",
    "型，但是样本的联合分布是难以获得的，而且也是难w精确拟合的。判别式模型 \n",
    "仅用来得到给定样本后的类别概率分布，具有明确的分类任务，能有效实现对不 \n",
    "同类别的差异识别，但无法反向得到X与y的先验分布，不过对样本的分布估计 \n",
    "要求不高。主流的产生式模型有HMM，MRF，马尔科夫链，LDA[55][56]等，而 \n",
    "判别式模型如贝叶斯判别模型，CRF模型，adaboost模型[57]增也有广泛应用。\n",
    "\n",
    "条件随机场是概率图模型，可以进行全局优化，在很多分类领域都有显著应 \n",
    "用，目前来说是最高效的监督训练的判别式模型，主要用于序列或关联信号的分 \n",
    "类。除了传统的直接利用样本x得到对应点标签y的类别条件概率，还引入了各 \n",
    "个样本点之间的类别转移与约束关系，举例就是一条船像素点的周围很大概率出 \n",
    "现的是天空或者水域类别，而出现汽车或者其他物体类别的概率相对低一些。对 \n",
    "于每种单元或成对特征函数都有对应系数来表示特征的权重，权重高的具有较大 \n",
    "的置信度。CRF模型可以获得平滑稳定的上下文信息，对关联信号的分类有着 \n",
    "极好的效果，比如文本标注，语音分类，图像分割等。 \n",
    "\n",
    "假定一幅图像X表示为区域块向量集合$\\{x_1,x_2,\\dots,x_l \\}$的形式，对每一块i，$\\phi_i$表示第i块提取的特征向量，$\\phi (x) = \\{\\phi_1(x),\\phi_2(x),\\dots,\\phi_i(x)\\}$，对应的类别为 $y=\\{y_1,y_2,\\dots,y_i,\\},\\ y_i \\in \\{ 0,1,\\dots,C \\}$，总计C种类别。类别对应输入样本的后验 \n",
    "概率分布[58]为； \n",
    "$$(3.1)\n",
    "p(y|\\phi(x)) \\propto p(y|\\phi(x)) = p(y)p(\\phi(x)|y)\n",
    "$$\n",
    "后验分布由式(3.1)表述，典型的判别式模型。当输入样本固定为某一特 \n",
    "定X时，而且参数也固定某值时，可知X的先验概率是固定的，故上式正比于 \n",
    "标签与样本的联合分布，根据概率学原理两个变量的联合分布为单个变量的边际 \n",
    "分布与另外一个变量的条件分布之乘积。大多数图像分类方法中各个像素点特征 \n",
    "向量之间作为条件独立而存在，但这在实际中几乎不可能，为了在分类时考虑到 \n",
    "周围区域即背景相关信息的类别对本区域的影响，人们开始研究CRF等背景相 \n",
    "关分类算法。 \n",
    "\n",
    "![图3.1基于区域的CRF模型]()\n",
    "图3.1基于区域的CRF模型 \n",
    "\n",
    "如上图为基于超像素块区域的CRF模型。每个区域提取区域的大小形状无 \n",
    "关的区域统计特征，每个区域都是颜色上较平滑一致的像素点聚集块，映射在图 \n",
    "中的每个节点，而各个邻接像素块的相互影响或约束由相应的成对势函数表示。 \n",
    "\n",
    "S表示原图像划分的所有区域，Ni表示第i块区域的邻接区域集合，则当输 \n",
    "入样本为X时其对应类别序列y的后验概率的指数分布形式如下式(3.2)： \n",
    "$$(3.2)\n",
    "$$\n",
    "其中$A_i和I_{ij}$分别表示单元势函数和成对势函数，$A_i$表示给定输入样本中某超像素块为$x_i$时块i是类别$y_i$的条件概率分布，$I_{ij}$表示超像素块i和j之间的 \n",
    "类别约束和类别变换的影响。$\\phi_i(x)$将块i的超像素块所有像素点颜色特征$x_i$提取 \n",
    "为区域相关的特征向量，输入样本$x$可由超像素块的特征向量集合$\\phi(x) = \\{\\phi_1(x),\\phi_2(x),\\dots,\\phi_M(x)\\}$表示，$\\mu(\\phi_i(x),\\phi_(x))$是成对块(i,j)构成的联合特征向量。如式(3.3)，Z(x)是归一化常数，目的是将数值归一化到标准概率 \n",
    "大小，表示某样本X产生的先验概率。 \n",
    "$$(3.3)\n",
    "Z(x)=\n",
    "$$\n",
    "一般实际应用中，单元势函数$A_i(y_i,\\phi_i(x)$和成对势函数 \n",
    "$I_{ij}\\big(y_i,y_j,\\mu(\\phi_i(x),\\phi_j(x)\\big)$大多仅限定与对应的超像素块xi或者xj相关，其中成 \n",
    "对势$I_{ij}$不仅仅与相邻超像素块类别$y_i和y_j$相关，也与对应的超像素块xi和xj \n",
    "的区域特征向量相关，本文中X为SAR图像的Pauli分解伪彩图。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1，单元势函数    \n",
    "单元势函数$A_i(y_i,\\phi_i(x))$主要表示对于给定某种超像素块特征其类别y的条 \n",
    "件概率分布，或者说当输入是xi而类别是y的置信度大小，而不考虑其他像素 \n",
    "块的影响。不管是单元势函数或者成对势函数，其分类器或者说类别概率分布产 \n",
    "生模型没有固定的形式，当然实际中为了计算方便会选择经典的分类器和模型， \n",
    "比如说成对势函数一般使用基于potts先验的上下文相关公式。\n",
    "\n",
    "通常利用logistic分类器[59]来表示单元势函数，多类别logistic分类器能够 \n",
    "根据输入信号输出具体毎种类别的概率分布即$\\hat{y_i}=arg\\ max_{y_i}p(y_i|\\phi(x))$。用其 \n",
    "作为CRF的单元势函数是很合理的，依据logistic分类的计算方法则单元势函 \n",
    "数可以表示成如下式(3.4): \n",
    "$$(3.4)$$\n",
    "式中区域特征向量$f_i(x)=[\\phi_{i1},\\phi_{i2},\\dots,\\phi_{iK},1]^T$，K表示为每个区域提取 \n",
    "的总的特征长度大小，f(x)对应的向量权重$w=[w_1,w_2,\\dots,w_K,\\alpha_1]^T$，而且对应于 \n",
    "每种类别分别有不同的w和偏置，其中$\\alpha_1$表示的是偏置权重。我们能够发现当 \n",
    "去掉成对势函数后，该CRF可退化成原始的多类别Logistic分类器计算方法。 \n",
    "\n",
    "2，成对势函数    \n",
    "CRF的成对势函数形如$I_{ij} \\big(y_i, y_j, \\mu(\\phi_i(x),\\phi_j(x))\\big)$表示的是i和j超像素块之 \n",
    "间的影响和类别传递关系，当然具体权重可能设定成与实际的像素块特征距离有 \n",
    "关，还有的与像素块索引的空间距离有关，一般是距离越远影响会变小，对于向 \n",
    "量差距的影响也符合上述原理。现在实际应用过程中一般利用统计物理学中的 \n",
    "potts模型，其与MRF关键的不同之处在于块i和块j不一定要求是相邻接的， \n",
    "即便是距离很远也会被考虑在内，该式的参数用来调节类别约束的各分量权重， \n",
    "参数一般是由监督训练得到，该方法的对数形式的公式如下式(3.5)： \n",
    "$$(3.5) $$\n",
    "\n",
    "式中$v=[v_1,v_2,\\dots,v_L]^T$对应于差分向量的每个分量的权值，当然最后一个分 \n",
    "量是偏差项的权值。$\\mu_{ij}(x) $一般选取为超像素块特征向量$x_i和x_j$的差分，而且最 \n",
    "后一项附带1，即$\\mu_{ij}=\\left[ |\\phi_i(x)-\\phi_j(x)|,\\ 1\\right]^T$。 \n",
    "\n",
    "成对势函数$\\sigma_{y_i y_j}(v^T\\mu_{ij}(x))$根据类别标号$y_i和y_k$的相同与不同会取截取不同 \n",
    "的块特征向量$\\mu_{ij}(x)$的部分参与计算，成对势函数不单单取决于特征向量的差分， \n",
    "实际上i，j处的类别标签对计算也有影响，如果类别标签一样的话会忽略向量的 \n",
    "绝对差值，只计算偏差项部分，如果不一样的话，那么将忽略偏差项，将会考虑 \n",
    "权重和对应的向量差分，仍然进行向量内积操作，分开来看的话，偏差项的大小 \n",
    "反映相邻区域属于同一类别的可能性加成，一般来说邻接区域的类别相同的可能 \n",
    "性强于不邻接区域。类别标号不一致一般反映区域属于不同物体，故存在特征向 \n",
    "量分布的不连续性，该式可以反映邻接区域会出现不同类别的先验概率的强度， \n",
    "具体数值与两区域块的特征向量距离有关，一般向量之间的空间差距很大的话， \n",
    "说明这两个区域块属于不同标签的置信度很大，这样的话会给邻接区域设定不同 \n",
    "类别时带来正比于特征向量差距的惩罚。 \n",
    "\n",
    "我们知道CRF需要样本来训练模型的参数，而且知道模型的参数后需要找 \n",
    "到最适合输入样本X的标签分布。一般来说，CRF的参数估计仍然基于极大似 \n",
    "然的原理，运用L-BFGS算法[60]来优化参数使得符合该样本的类别标注的概率为 \n",
    "最大，应用梯度下降法来一步步收敛使参数达到最佳。CRF推理就是在给定参 \n",
    "数下，求得最适合该样本的类别标注，即给定样本后分配各个区域的类别以使得 \n",
    "条件概率最大，为了减少运算次数，通常有MAP[61]和LBP[62]等方法，通过这些 \n",
    "方法可以显著降低运算次数，使问题解决变成可能。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 像素块特征提取 \n",
    "\n",
    "对于基于超像素块区域的特征提取要考虑到区域的内部均质性，提取的特征 \n",
    "应该反映区域的整体性质而与区域大小形状无关，对于SAR图像meanshift得到 \n",
    "的超像素块我们可以提取强度特征，纹理特征以及符合相关特性的的极化分解特 \n",
    "征。 \n",
    "\n",
    "1，强度特征 \n",
    "\n",
    "强度特征主要反映区域内像素点色度的分布规律和整体特性，最简单的如均 \n",
    "值，方差等都是基于每个像素点色度值的计算。 \n",
    "\n",
    "(1)灰度直方图 \n",
    "\n",
    "多极化SAR数据由HH，HV，VH，VV四种极化方式构成，HV和Vh是 \n",
    "对称的关系，如果仅用一种通道很多区域就会无法分辨，故目前最好的是采取 \n",
    "HH，HV，VV三通道数据，对每个通道的数据映射到0到255之间形成灰度图 \n",
    "像，将256阶的灰度分成16段区间，针对每个区域计算该区域的像素分布，并 \n",
    "根据灰度映射到对应的区间，这样我们可以得到灰度直方图，将每个区间的数量 \n",
    "最终除以该区域总的像素点数得到归一化的概率分布，可以得到16维度的归一 \n",
    "化概率分布特征，16个维度的值之和为1。\n",
    "\n",
    "(2)Haar特征\n",
    "\n",
    "Haar特征是基于不同矩形框内像素的强度值之和的差异来计算的，图3.2显 \n",
    "示了 Haar特征使用的矩形框位置特征模板。首先图像中有白色和黑色的区域， \n",
    "而且对应于某一中也点的矩形框需要设定合适的大小，然后需要分别统计白色区 \n",
    "域和黑色区域像素点灰度么和，接着将白色区域灰度之和减去黑色区域灰度之和， \n",
    "最后将其除以矩形框的总的像素灰度之和进行归一化操作，这样就得到了某一模 \n",
    "板的Haar特征，一共有七个模板。之后再针对每个像素块执行均值操作即可， \n",
    "每个区域可以得到7个维度特征。 \n",
    "\n",
    "![图3.2 Haar特征模板]()\n",
    "图3.2 Haar特征模板 \n",
    "\n",
    "2，纹理特征 \n",
    "\n",
    "纹理特征一般选择多种滤波器多种尺度扫描图像得到，之后在每个超像素 \n",
    "块取均值即可，传统的滤波器包括髙斯滤波器，x或y方向衍生高斯滤波器，拉 \n",
    "普拉斯滤波器等，针对SAR伪彩色图像的特征提取，有人组合了17个滤波器组 \n",
    "以得到17维度的纹理特征向量取得了很好的效果。 \n",
    "\n",
    "3，极化分解特征 \n",
    "\n",
    "SAR雷达通过多极化的方法得到的数据一般是2x2的矩阵[63]形式，该矩阵 \n",
    "的值主要因为雷达发射信号呈现水平和垂直两种方向的波，雷达接收天线也是呈 \n",
    "现水平和垂直的方向故有四种极化波，包含HV，HH，VH，VV这四个数值， \n",
    "该矩阵反映了目标物体的相位特性，散射特性，矩阵的值都是复数形式，故具有 \n",
    "幅度和相位信息，目标不同的结构和本身的后向散射特性如介电常数，表面渗透 \n",
    "率以及雷达和物体的空间朝向，相对位置等都会导致矩阵各值的不同。 \n",
    "\n",
    "在选定的正交极化基$(H,V)$下，雷达的发射电磁波矢量$\\vec{E}^T$和接收电磁波矢 \n",
    "量$\\vec{E}^R$可以分别表示为： \n",
    "$$(3.6) \\vec{E}^T = \\vec{E_h^T e_h} + \\vec{E_v^T e_v}$$\n",
    "$$(3.7) \\vec{E}^R = \\vec{E_h^R e_h} + \\vec{E_v^R e_v}$$\n",
    "$\\vec{E}^T$和$\\vec{E}^R$的关系可以表示为； \n",
    "$$(3.8)$$\n",
    "式(3.8)中，r为散射目标与接收天线么间的距离，$k_0$为电磁波波数。极 \n",
    "化散射矩阵S表示为式(3.9)： \n",
    "$$(3.9) $$\n",
    "其中$S_{HH}和S_{VV}$表示同极化分量，在互易条件下，$S_{HH}=S_{VV}$，表示交叉极化 \n",
    "分量。 \n",
    "\n",
    "Pauli分解[13]是在正交线性基下，用Pauli基对地物目标的散射矩阵进行的分 \n",
    "解。Pauli基包括四个参数$\\{ [S_a],[S_b],[S_c],[S_d] \\}$，具体形式如下: \n",
    "$$(3.10)[S_a]=\\frac{1}{2}$$\n",
    "根据相干分解的原理，散射矩阵[S]可以表示为： \n",
    "$$(3.11)[S]=$$\n",
    "当测量系统为单基系统，且满足互易定理时，即$S_{HV}=S_{VH}$散射矩阵分解 \n",
    "为：\n",
    "$$(3.12) $$\n",
    "\n",
    "式(3.12)中$|a|^2$冲表示单次散射的能量，$|b|^2$表示具有二面角散射特性的散射 \n",
    "体的能量，$|c|^2$表示具有倾斜45°二面角散射特性的散射体的能量。此外还有SDH\n",
    "分解和Huynen分解等特征分解方法，在此不多介绍。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于后置CRF的deeplab模型 \n",
    "\n",
    "### deeplab的CRF结构 \n",
    "\n",
    "低级别的图像处理任务比如图像分割或图像深度评估经常需要对每个点分 \n",
    "配类别标签。针对于单个像素点类别分类的特征提取是一个很重要的课题和任务。 \n",
    "同样的考虑一些重要因素比如图像边缘，空间连续性，表象连续性的影响来分配 \n",
    "类别会使结果更加精确。 \n",
    "\n",
    "设计出一个强大的像素级特征表达对于点的分类至关重要，以往的方法如纹 \n",
    "理森林，随机森林效果一般。由于最近的监督式深度学习方法如CNN在髙级图 \n",
    "像识别和检测上得到广泛应用，所以FCN被设计用来使CNN可以对每个像素点 \n",
    "分类。无数的基于CNN的分类器在像素级分类任务上效果显著，然而，对于FCN \n",
    "用于像素级分类也有很多缺点。首先，传统的FCN卷积层的卷积核有极大的感 \n",
    "受野，因此对于单个像素点有着极大的模糊输出，对于单像素点分类是很大的误 \n",
    "差来源。此外，pooling层的降维功能也对点的分类产生极大干扰。因此很多FCN \n",
    "结果产生的分割结果会出现模糊不规则的边缘和块状的分割区域。第二，FCN \n",
    "缺少平滑约束，该约束有利于使分割结果趋向于相似的像素，空间与表象的连续 \n",
    "分布。没有平滑约束会导致分割结果中错误的物体边缘和虚假的微小区域。 \n",
    "\n",
    "概率图模型在各种场合的应用己被证实可有效提高分类正确率。MRF和 \n",
    "CRF在诸多信号分类领域都表现出极强的分类辨别能力，尤其是图像分类与分 \n",
    "割中。图像分割的CRF推理中的关键因素就是将类别标号问题转变成概率推理 \n",
    "问题，其中考虑到如周围相似像素点的促进作用。CRF可以将模糊和不显著的 \n",
    "像素级类别标注提取成锐利的边缘分布和细腻的分割结果。因此，CRF可以用 \n",
    "来解决FCN中模糊输出而产生分类误差的问题，FCN一般依靠梯度下降算法来训 \n",
    "练，一般上将CRF作为后置[64]的处理加在FCN的结果上来改善分割的结果， \n",
    "deeplab是此种方式的典范。 \n",
    "\n",
    "假设$x_i$，代表点i的类别标签，具有L种类别。假设x是$x_1到x_n$形成的向量， \n",
    "n为图像的点数。I代表图像数据，则基于吉布斯分布的CRF可被用来描述上述 \n",
    "关系式$p(X=x|I)=\\frac{1}{Z(I)\\exp(-E(x|I))}$，这里E(x)表示某x标签的能量，Z(I)表 \n",
    "示归一化函数。 \n",
    "\n",
    "在全连接CRF模型中，X的能量分布式由下式表述： \n",
    "$$(3.13)E(x)=\\sum$$\n",
    "\n",
    "－元的组件表示点i被分配类别$x_i$的反概率(或代价)。成对能量组件表示 \n",
    "同时分配点i，j为标签$x_i,x_j$的代价。一元组件的值来源于FCN，FCN不考虑 \n",
    "点类别分配的平滑性与连续性，成对组件提供基于图像数据的平滑规则，鼓励将 \n",
    "同属性的点分配同样的类别。我们将成对组件建立成如下基于髙斯核的模型。 \n",
    "$$(3.14)$$\n",
    "\n",
    "在这里对于M个，是用在特征向量的高斯核。$f_i$表示点i的特征向量比如 \n",
    "RGB颜色值或者二维坐标。函数$\\mu()$是类别适应度函数，表示成对组件的类 \n",
    "别适应度矩阵。最小化CRF的能量函数E(x)得到最符合该图像的类别标记。 \n",
    "由于精确的最小化上述函数是棘手的，平均场的对于CRF分布的近似方法用于 \n",
    "近似最大后验概率的边际推理。这个利用简单的Q(x)分布来获取精确的实际P(x) \n",
    "分布，Q(x)的能够写成独立的边际分布的形式，利用迭代算法来优化后验概率的推 \n",
    "理精度。平均场推理基于髙斯空间核与高斯双边核，这些核参数通过实现人为设 \n",
    "定，对于分割结果空间和表象的连续性有重要作用。 \n",
    "\n",
    "deeplab[65]主要的创新点在后面的CRF部分，为了达到类似于传统CRF的 \n",
    "全局优化效果，利用了循环的方法，上一次的输出为下一次的输入，其中采用的 \n",
    "CRF架构是基于如full connect CRF[66] 的全局连接模型，意味着图像上所有的点对 \n",
    "其他点都有或多或少的影响，具体由高斯距离核函数控制，如图3.3所示，各项 \n",
    "参数由训练得到。Qin为上次迭代结果，I为图像数据，U为FCN的结果，Qout \n",
    "为本次迭代输出。 \n",
    "\n",
    "![图3.3deeplab的单次计算过程]\n",
    "图3.3deeplab的单次计算过程 \n",
    "\n",
    "如下是该计算的具体细节，下式为第一次迭代的初始概率值，由U归一化 \n",
    "得到，其中U是FCN的结果，i为像素点序号，l为类别，$Z_i$为归一化常数，这 \n",
    "个步骤相当于将U的每个像素点运用了 softmax函数，此函数在FCN中早以得 \n",
    "到广泛应用，此操作不需要任何新的参数。 \n",
    "$$(3.15)$$\n",
    "$$(3.16)$$\n",
    "$$(3.17)$$\n",
    "\n",
    "式(3.16)为概率转移函数，该式表示对于某一点i的某一类别1，所有图像 \n",
    "上的其他点都会对该点的有一定的转移作用，$k^{(m)}(f_i,f_j)$代表高斯核函数控制转 \n",
    "移强度，式(3.17)为权值调整，w对应于所使用的高斯核的总体强度巧制，m\n",
    "代表使用的高斯核函数的个数。高斯核距离反映的是点与点之间关联的程度，由 \n",
    "于CRF时全图相关的，也就是说高斯核的感受野是整个图像范围，这使得用蛮 \n",
    "力执行高斯滤波不可行。好在Permutohedral  lattice技术可以 有效解决高尺度高斯 \n",
    "滤波问题，使得计算复杂度只与点的数量线性相关。在误差反传时，输入节点的 \n",
    "误差倒数是通过反向套用M个高斯核与输出节点的误差导数，故反向误差传播 \n",
    "复杂度与正向计算一致。传统上使用高斯双边核与高斯空间核，并为了简单计算 \n",
    "保持核函数的参数不变。下一步则是对于每个类别分别将M个滤波器结果加枚 \n",
    "相加，每个类别都是独立的，相当于有M个输入通道1个输出通道的卷积核为 \n",
    "1x1的卷积操作，对于每个l都有对应的w，故相加权重有2＊l个，每个权重都 \n",
    "可以训练得到。 \n",
    "\n",
    "如下式(3.18)和式(3.19)是两个高斯核的具体算式： \n",
    "$$(3.18)$$\n",
    "$$(3.19)$$\n",
    "$p_i和p_j$表示i和j处的二维位置坐标向量，$I_i和I_j$表示颜色RGB向量，第 \n",
    "一个式子联合考虑距离和颜色差距，距离和颜色差距越大值越小影响越小，第二 \n",
    "个式子单独考虑距离差距带来的影响，距离越远值越小影响越小，三个核函数参 \n",
    "数$\\theta_{\\alpha,\\beta,\\gamma}$一般人为设定。\n",
    "\n",
    "$$(3.20)$$\n",
    "\n",
    "式(3.20)表示类别转移操作，由于不同类别变成其他类别时会有不同的兼 \n",
    "容度和适应性，此时用表示一个类别变成另外类别的相容度信息矩阵，注意这里， \n",
    "表示类别相容度对类别的次序敏感，正向与反向并不相同，类别相容度矩阵由 \n",
    "FCN8结果或输入的信号统计求得。$\\mu$代表两种类别的相容度，在传统potts模 \n",
    "型中$\\mu$代表给相似性质的像素点对赋予不同的类别时带来的固定惩罚，此模型关 \n",
    "键问题在于对每个类别对赋予了相同的惩罚，实际上不同类别的转移惩罚有很大 \n",
    "差别。比如说，对于将人和自行车分配到相邻的点时应该具有较小的惩罚值，而 \n",
    "将天空和自行车分配到相邻点应该具有较大的惩罚。所以，从样本中得到相容度 \n",
    "信息比potts模型中直接人工设定一个固定值更为符合实际情况。类别转移操作 \n",
    "可被视为L个输入与输出节点的而且卷积核尺度为1x1的卷积操作。\n",
    " \n",
    "$$(3.21)$$ \n",
    "\n",
    "式(3.21)代表概率整合的操作，最终概率由条件似然概率U和全局先验概 \n",
    "率$\\hat{Q_i}(l)$相减得到，U为FCN8得到的类别概率分布，此步骤不渉及任何参数，误 \n",
    "差反传可以简单在输出误差上加上负号即可。\n",
    "\n",
    "$$(3.22)$$\n",
    "\n",
    "式(3.22)代表归一化操作，然后当 \n",
    "做下次循环的输入。注意这里减或加无区别，依赖相容度矩阵来调节具体正负。 \n",
    "\n",
    "$$(3.23)$$\n",
    "$$(3.24)$$\n",
    "$$(3.25)$$\n",
    "\n",
    "deeplab的后置CRF部分采取循环计算的方式，如公式(3.23)到式(3.25) \n",
    "所示，为了达到全局优化的结果，不断优化目标使其趋于总体优化目标，每次计 \n",
    "算的结果会被下一次循环当作新的输入，通过不断调整平衡自身的条件似然概率 \n",
    "和考虑到周围的先验分布信息，以达到类似于全图优化的结果。 \n",
    "\n",
    "softmax主要用来在开始第一次循环时用条件似然概率U (实际上由FCN8 \n",
    "得到)来初始化输入，之后按照前面的输出变下一次的输入的计算原则，T在实 \n",
    "际操作中一般取5。$f_\\theta$表示式(3.16)到式(3.22)的一次迭代过程，Y为最终输出并 \n",
    "只在最后一次循环输出。针对图像信号带来的整体概率分布，可简单的将每个节 \n",
    "点的概率分布相乘，对于最优化的类别分配，只需要针对每个节点取对应的最大 \n",
    "的输出概率类别节点即可。之所可以将整体优化的CRF过程变成分离的单个 \n",
    "节点优化相乘的形式，是因为每次迭代过程中每个节点就考虑了周围节点的影响， \n",
    "迭代过程就是在考虑周围点对该节点的最终影响，迭代次数越多，最终整体结果 \n",
    "如式(3.26)所示，得到的值就越接近全局优化下的该点分立值。 \n",
    "$$(3.26) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deeplab模型训练 \n",
    "deeplab之前的一些后置CRF优化方法采用梯度下降法[67,68]，而deeplab\n",
    "的后置CRF采用的是网格优化法，只有正向操作，没有误差反向传递过程，由 \n",
    "每个参数序列生成结果，将结果最好的参数取值保存下来即为后的CRF参数 \n",
    "不再改变，具体方法是将所有相关参数分别设定一个范围，然后选择合适的间距 \n",
    "划分网格，对所有分立值采取循环遍历的形式，选择其中对训练样本有最高的整 \n",
    "体正确率值的参数设定，并保留该参数作为CRF层的固定参数。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于边缘区域变换的DT网络 \n",
    "### DT 网络 \n",
    "CNN衍生的FCN等对于场景语义分割十分有效，主要任务是对图像中的每 \n",
    "个点分配一个类别标签。最近对FCN的后处理操作如加上全连接CRF能有效改 \n",
    "善分割精度和物体边缘信息，全连接CRF的概率转移对双边滤波器的应用是对 \n",
    "边缘敏感的，对中心点距离较近化及颜色相近的转移系数较大，表示可能有相同 \n",
    "类别，实际应用过程中可以使分割结果比较符合物体的实际边缘[69]。 \n",
    "\n",
    "为了进一步较好的改善边缘信息，在使用deeplab的CRF之前，应用DT \n",
    "算法[70]的递归方程在图像行列的序列信号上，该递归方程对边缘敏感，所有扩 \n",
    "散在边缘处停止。区域变换即DT可以看做RNN网络的特例，可以方便的表示 \n",
    "为GRU单元。扩散操作与边缘强度图有密切关联，在标准DT模型中边缘强度 \n",
    "由颜色梯度得到，但我们将从FCN中心层学习得到该强度值，重要的是我们可 \n",
    "以从端对端的训练中得到内部边缘网络的卷积核权重，以得到样本相关的边缘滤 \n",
    "波器。 \n",
    "\n",
    "DT网络[71]的模型由三部份组成，它们首尾并接的连接在一起训练，共同优 \n",
    "化最后的分割结果的精度。第一个组件基于Vgg16[72]结构的FCN8得到粗略的 \n",
    "分割预测的得分。第二个细件被称为内部边缘网络，该网络利用FCN8的中间层 \n",
    "得到的特征，这些特征层在被堆叠么前被会填充到同样的空间尺度，一个卷积核 \n",
    "为1x1尺度的只有1个输出通道的卷积层被用来作为边缘强度预测，后接上 \n",
    "RELU层用来使输出在0到1的范围。第三个组件是DT网络，这是一个保留边 \n",
    "缘信息的滤波器，通过分别在行和列上套用一维递归滤波器实现高效的操作。尽 \n",
    "管DT传统上用作普通的图像处理，我们用它来过滤粗略的FCN分割结果得分 \n",
    "使其与物体边缘结合得更好，通过内部边缘网络得到的边缘强度图。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 边缘区域变换算法 \n",
    "DT(区域变换)网络需要2个输入，粗略的待滤波输入信号x，在我们的案 \n",
    "例中就是FCN8得到的初步分割结果得分，另一个是正相关的区域变换转移密度 \n",
    "信号d。输出信号是滤波后信号y。对于一维的N长度信号，如式(3.27)设置$y_l=x_l$\n",
    "并循环i＝2,...,N计算输出信号 \n",
    "$$(3.27) $$\n",
    "权重wi取决于区域变换密度$d_i$表示为式(3.28)： \n",
    "$$(3.28) $$\n",
    "$\\sigma_s$代表空间区域的卷积核标准差，区域变换密度$d_i$决定了扩散范围，通过 \n",
    "控制$x_i$，和前一个滤波后信号$y_{i-1}$的相加比例得到当前信号$y_i,w_i$处于0到1的范 \n",
    "围，控制点i-1到i的信号传递强度，如果$d_i$十分小，我们会得到全扩散，$y_i=y_{i-1}$\n",
    "以及$w_i=1$。另一个极端是$d_i$的值十分大，此时$w_i=0$，扩散终止，导致$y_i=x_i$\n",
    "可以见到一维信号如果只沿着一个方向如从左到右，那么下个信号将只取决 \n",
    "于前一信号，为解决此问题可以从左到右和从右到左来滤波两次。 \n",
    "对于二维信号的区域变换，在每个信号维度用一维滤波器循序的滤波，分别 \n",
    "从上到下，从下到上，从左到右，从右到左四个方向顺序滤波，之后整体进行K\n",
    "次循环来减小误差。我们减小每次循环的DT卷积核的标准差，如式(3.29)，每 \n",
    "次第k次用$\\sigma_k$代替$\\sigma_s$，来计算$w_i$。 \n",
    "$$(3.29)\\sigma_k=\\sigma_s$$\n",
    "区域变换密度$d_i$定义为式(3.30)； \n",
    "$$(3.30) $$\n",
    "$g_i$代表边缘强度，$\\sigma_s$是边缘强度图的卷积核标准差，$g_i$越大，代表点i越 \n",
    "可能是一个边缘点因此扩散在此终止，通用的DT网络使用颜色梯度如式(3.31)： \n",
    "$$(3.31) g_i=\\sum_{c=1}^{3}$$\n",
    "\n",
    "我们的想法是通过反向传递输出y的分割误差到两个输入，这使得我们将 \n",
    "DT转化为神经网络层，我们因此可以联合训练FCN8的粗略的分割结果x和边 \n",
    "缘强度g的相关参数。\n",
    "\n",
    "我们假定每个点$y_i$不仅影响接下来的点$y_{i+1}$，还作为一个子层的输入，因此 \n",
    "反向传递时除了考虑点$y_{i+1}$的误差反传外也接受子层的反向误差。与标准的反向 \n",
    "传播类似，我们反向递归套用式(3.32)到式(3.34)，更新参数y，w， x的相 \n",
    "应偏导数。 \n",
    "$$(3.32)$$ \n",
    "$$(3.33)$$\n",
    "$$(3.34) $$\n",
    " \n",
    "由于权重$w_i$，在四个方向的滤波中以及K次循环中都是共享的，所以每次的 \n",
    "偏导数都应该相加作为整体。用这些偏导数我们能够得到边缘强度图的偏导 \n",
    "数，通过链式规则得到$g_i$的偏导数如下式所示，L表示目标误差函数。 \n",
    "$$(3.35) $$\n",
    "$$(3.36) $$\n",
    "这些偏导数之后会被传入内部边缘网络，这是用来得到边缘强度预测值的。 \n",
    "我们还可以建立与门控RNN[73]单元的联系，该RNN起初用来分类序列文本数据， \n",
    "此RNN有如下规则 \n",
    "$$(3.37) $$\n",
    "该式(3.37)中，$z_i=1-w_i,\\hat{y_i}=x_i,z_i$被定义为$z_i=\\sigma(f_i),f_i$是激励信号， \n",
    "以及激励函数$\\sigma(t)=1/(1+e^{-t})$，因此可以得到DT中边缘强度图$g_i$和激励信号$f_i$\n",
    "的关系如下： \n",
    "$$(3.38)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本章小结 \n",
    "本章主要介绍了传统的CRF计算过程和CRF的基本原理和传统方法块特征 \n",
    "提取的特征描述，介绍了强度，纹理，极化矩阵特征，然后介绍了基于后接全连 \n",
    "接CRF计算的原理的deeplab网络，描述了全连接CRF的计算过程，最后介绍 \n",
    "DT网络的原理和其基本算法，不过其具体分析和改进留在第4章说明。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2像素块特征提取 \n",
    "对于基于超像素块区域的特征提取要考虑到区域的内部均质性，提取的特征 \n",
    "应该反映区域的整体性质而与区域大小形状无关，对于SA民图像meanshift得到 \n",
    "的超像素块我们可以提取强度特征，纹理特征以及符合相关特性的的极化分解特 \n",
    "征。 \n",
    "1，强度特征 \n",
    "强度特征主要反映区域内像素点色度的分布规律和整体特性，最简单的如均 \n",
    "值，方差等都是基于每个像素点色度值的计算。 \n",
    "(1)灰度直方图 \n",
    "多极化SAR数据由hh，hV，Vh，VV四种极化方式构成，hV和Vh是 \n",
    "对称的关系，如果仅用一种通道很多区域就会无法分辨，故目前最好的是采取 \n",
    "hh， hV，VVh通道数据，对每个通道的数据映射到0到255之间形成灰度图 \n",
    "像，将256阶的灰度分成16段区间，针对每个区域计算该区域的像素分布，并 \n",
    "根据灰度映射到对应的区间，这样我们可以得到灰度直方图，将每个区间的数量 \n",
    "最终除w该区域总的像素点数得到归一化的概率分布，可以得到16维度的归一 \n",
    "化概率分布特征，16个维度的值之和为1。 \n",
    "口)hAAr特征 \n",
    "hAAr特征是基于不同矩形框内像素的强度值之和的差异来计算的，图3.2显 \n",
    "示了 hAAr特征使用的矩形框位置特征模板。首先图像中有白色和黑色的区域， \n",
    "而且对应于某一中也点的矩形框需要设定合适的大小，然后需要分别统计白色区 \n",
    "域和黑色区域像素点灰度么和，接着将白色区域灰度之和减去黑色区域灰度之和， \n",
    "最后将其除w矩形框的总的像素灰度之和进行归一化操作，这样就得到了某一模 \n",
    "板的hAAr特征，一共有屯个模板。之后再针对每个像素块执行均值操作即可， \n",
    "每个区域可以得到7个维度特征。 \n",
    "3国田田田田gh \n",
    "hAAr－h\n",
    " hAAr－V\n",
    " hAAr－d hAAr－tl hAAr－tr hAAr－Bl hAAr－B 巧 \n",
    "图3.2 hAAr特征模板 \n",
    "22 \n",
    "2，纹理特征 \n",
    "纹理特征一般选择多种滤波器多种尺度扫描图像得到，之后在每个超像素 \n",
    "块取均值即可，传统的滤波器包括髙斯滤波器，X或y方向衍生高斯滤波器，拉 \n",
    "普拉斯滤波器等，针对SAR伪彩色图像的特征提取，有人组合了 17个滤波器组 \n",
    "{＾得到17维度的纹理特征向量取得了很好的效果。 \n",
    "3，极化分解特征 \n",
    "SAR雷达通过多极化的方法得到的数据一般是2X2的矩阵63张式，该矩阵 \n",
    "的值主要因为雷达发射信号呈现水平和垂直两种方向的波，雷达接收天线也是呈 \n",
    "现水平和垂直的方向故有四种极化波，包含hV， hh， Vh， VV这四个数值， \n",
    "该矩阵反映了目标物体的相位特性，散射特性，矩阵的值都是复数形式，故具有 \n",
    "幅度和相位信息，目标不同的结构和本身的后向散射特性如介电常数，表面渗透 \n",
    "率以及雷达和物体的空间朝向，相对位置等都会导致矩阵各值的不同。 \n",
    "在选定的正交极化基(w，n下，雷达的发射电磁波矢量去f和接收电磁波矢 \n",
    "量去＊可以分别表示为： \n",
    "玄巧之＊ ＋巧＾\n",
    " (3.6) \n",
    "育＝巧—卽＋巧一e，\n",
    " (3.7) \n",
    "左f和左k的关系可以表示为； \n",
    "－\n",
    "刮片h Sw「巧\n",
    "＿皆＿｜— r uw SJiX」\n",
    " t \n",
    "式(3.8)中，r为散射目标与接收天线么间的距离，Ad为电磁波波数。极 \n",
    "化散射矩阵S表示为式(3.9)： \n",
    "；叫\n",
    " (3.9) \n",
    "其中Sw和Sw表示同极化分量，在互易条件下，Sw＝Sw，表示交叉极化 \n",
    "分量。 \n",
    "Pauli分解[u诣在正交线性基下，用Pauli基对地物目标的散射矩阵进行的分 \n",
    "解。Pauli基包括四个参数{[S。]，[S＊]，口。]，[＆]}，具体形式如下 \n",
    "剧＝诚：]，[w ＝走[；句 0.w \n",
    "23  \n",
    "閒二去[：江防]＝去[：〇＇ \n",
    "根据相干分解的原理，散射矩阵[S]可以表示为： \n",
    "[小「产訂＝。闷＋化]＋啦]＋啦] 口.11) \n",
    "当测量系统为单基系统，且满足互易定理时，即＝ 散射矩阵分解 \n",
    "为： \n",
    "[巧＝「子＂；叫＝4＆] ＋啦]＋ 化]\n",
    " (3.12) \n",
    "＿\n",
    "＾Vh\n",
    " ＿ \n",
    "式(3.12)中｜冲表示单次散射的能量，忡表示具有二面角散射特性的散射 \n",
    "体的能量，｜c｜2表示具有倾斜45°二面角散射特性的散射体的能量。此外还有Sdh \n",
    "分解和huynen分解等特征分解方法，在此不多介绍。 \n",
    "3.2基于后置CRF的deeplab模型 \n",
    "3.2.1 de巧lAB 的 CRF 结构 \n",
    "低级别的图像处理任务比如图像分割或图像深度评估经常需要对每个点分 \n",
    "配类别标签。针对于单个像素点类别分类的特征提取是一个很重要的课题和任务。 \n",
    "同样的考虑一些重要因素比如图像边缘，空间连续性，表象连续性的影响来分配 \n",
    "类别会使结果更加精确。 \n",
    "设计出一个强大的像素级特征表达对于点的分类至关重要，(＾＞1往的方法如纹 \n",
    "理森林，随机森林效果一般。由于最近的监督式深度学习方法如CNN在髙级图 \n",
    "像识别和检测上得到广泛应用，所1＾ FCN被设计用来使CNN可｜＾＞1对每个像素点 \n",
    "分类。无数的基于CNN的分类器在像素级分类任务上效果显著，然而，对于FCN \n",
    "用于像素级分类也有很多缺点。首先，传统的FCN卷积层的卷积核有极大的感 \n",
    "受野，因此对于单个像素点有着极大的模糊输出，对于单像素点分类是很大的误 \n",
    "差来源。此外，pooling层的降维功能也对点的分类产生极大干扰。因此很多FCN \n",
    "结果产生的分割结果会出现模糊不规则的边缘和块状的分割区域。第二，FCN \n",
    "缺少平滑约束，该约束有利于使分割结果趋向于相似的像素，空间与表象的连续 \n",
    "分布。没有平滑约束会导致分割结果中错误的物体边缘和虚假的微小区域。 \n",
    "24 \n",
    "概率图模型在各种场合的应用己被证实可有效提高分类正确率。MRF和 \n",
    "CRF在诸多信号分类领域都表现出极强的分类辨别能力，尤其是图像分类与分 \n",
    "割中。图像分割的CRF推理中的关键因素就是将类别标号问题转变成概率推理 \n",
    "问题，其中考虑到如周围相似像素点的促进作用。CRF可以将模糊和不盈著的 \n",
    "像素级类别标注提取成锐利的边缘分布和细腻的分割结果。因此，CRF可以用 \n",
    "来解决FCN中模糊输出而产生分类误差的问题，FCN—般依靠梯度下降算法来训 \n",
    "练，一般上将CRF作为后置心]的处理加在FCN的结果上来改菩分割的结果， \n",
    "deeplab是此种方式的典范。 \n",
    "假设X，代表点i的类别标签，具有l种类别。假设X是：c，到：c。形成的向量， \n",
    "n为图像的点数。i代表图像数据，则基于吉布斯分布的CRF可被用来描述上述 \n",
    "关系式＝ X…＝＾＾eXp(－巧Xi巧)，这里e(X)表示某X标签的能量，Z(i)表 \n",
    "示归一化函数。 \n",
    "在全连接CRF模型中，X的能量分布式由下式表述： \n",
    "ew ＝\n",
    " A)\n",
    " (3.13) ＊\n",
    " i＜J \n",
    "－元的组件表示点i被分配类别X，的反概率(或代价)。成对能量组件表示 \n",
    "同时分配点i，J为标签X，，X，的代价。一元组件的值来源于FCN，FCN不考虑 \n",
    "点类别分配的平滑性与连续性，成对组件提供基于图像数据的平滑规则，鼓励将 \n",
    "同属性的点分配同样的类别。我们将成对组件建立成如下基于髙斯核的模型。 \n",
    "知 X，) ＝ //知气)Zw(M)皆 ＞(乂，乃)\n",
    " 口.14) \n",
    "历《1 \n",
    "在这里对于M个，是用在特征向呈的高斯核。/表示点i的特征向量化如 \n",
    "RGB颜色值或者二维坐标。函数u 0是类别适应度函数，表示成对组件的类 \n",
    "别适应度矩阵。最小化CRF的能量函数e (X)得到最符合该图像的类别标记。 \n",
    "由于精确的最小化上述函数是棘手的，平均场的对于CRF分布的近似方法用于 \n",
    "近似最大后验概率的边际推理。这个利用简单的q(X)分布来获取精确的实际p(X) \n",
    "分布，q的能够写成独立的边际分布的形式，利用迭代算法来优化后验概率的推 \n",
    "理精度。平均场推理基于髙斯空间核与高斯双边核，这些核参数通过实现人为设 \n",
    "定，对于分割结果空间和表象的连续性有重要作用。 \n",
    "25  \n",
    "deeplAw63主要的创新点在后面的CRF部分，为了达到类似于传统CRF的 \n",
    "全局优化效果，利用了循环的方法，上一次的输出为下一次的输入，其中采用的 \n",
    "CRF架构是基于如1 connect CRF[66惭全局连接模型，意味着图像上所有的点对 \n",
    "其他点都有或多或少的影响，具体由高斯距离核函数控制，如图3.3所示，各项 \n",
    "参数由训练得到。qin为上次迭代结果，i为图像数据，u为FCN的结果，qout \n",
    "为本次迭代输出。 \n",
    "u \n",
    "qin i 以\n",
    " qout－f 0 化 qin，。 \n",
    "解織马雛脯马麵微与概雜合与归－化广—： ＞ 丄勺 i i i i i i \n",
    "图3.3 deepl油的单次计算过程 \n",
    "如下是该计算的具体细节，下式为第一次迭代的初始概率值，由u归一化 \n",
    "得到，其中u是FCN的结果，i为像素点序号，/为类别，为归一化常数，这 \n",
    "个步骤相当于将u的每个像素点运用了 softmax函数，此函数在FCN中早w得 \n",
    "到广泛应用，此操作不需要任何新的参数。 \n",
    "qi(/) ＝去紋口剛)\n",
    " (3.巧 \n",
    "式(3.16)为概率转移函数，该式表示对于某一点i的某一类别1，所有图像 \n",
    "上的其他点都会对该点的有一定的转移作用，心，方)代表高斯核函数控制转 \n",
    "移强度，式(3.17)为较值调整，w对应于所使用的高斯核的总体强度巧制，M \n",
    "代表使用的高斯核西数的个数。高斯核距离反映的是点与点之间关联的程度，由 \n",
    "于CRF时全图相关的，也就是说高斯核的感受野是整个图像范围，这使得用蛮 \n",
    "力执行高斯滤波不可行。好在perMutohedrAl lAttice技术可{＾＞1有效解决高尺度高斯 \n",
    "滤波问题，使得升算复杂度只与点的数量线性相关。在误差反传时，输入节点的 \n",
    "误差倒数是通过反向套用M个高斯核与输出节点的误差导数，故反向误差传播 \n",
    "复杂度与正向计算一致。传统上使用高斯双边核与高斯空间核，并为了简单计算 \n",
    "保持核函数的参数不变。下一步则是对于每个类别分别将M个滤波器结果加枚 \n",
    "相加，每个类别都是独立的，相当于有M个输入通道1个输出通道的卷积核为 \n",
    "26 \n",
    "1X1的卷积操作，对于每个/都有对应的w，故相加权重有2＊/个，每个权重都 \n",
    "可以训练得到。 \n",
    "￣ (M) \n",
    "0＇ (/)二 Z片/M)(成方)0/(＇)\n",
    " (3.16) \n",
    "￣ (w) \n",
    "如) ＝ ！＞(＂) A (/)\n",
    " (3.17) \n",
    "如下式(3.18)和式(3.19)是两个高斯核的具体算式： \n",
    "以 ＼pi￣pJf\n",
    " …。、 eXp(－－＾＾＾ 口竭 \n",
    "eXp(口.1叫 \n",
    "A和A.表示i和J处的二维位置坐标向量，/，.和//表示颜色民gB向量，第 \n",
    "一个式子联合考虑距离和颜色差距，距离和颜色差距越大值越小影响越小，第二 \n",
    "个式子单独考虑距离差距带来的影响，距离越远值越小影响越小，三个核函数参 \n",
    "数0。，，.，—般人为设定。\n",
    " 、 \n",
    "式(3.20)表示类别转移操作，由于不同类别变成其他类别时会有不同的兼 \n",
    "容度和适应性，此时用表示一个类别变成另外类别的相容度信息矩阵，注意这里， \n",
    "表示类别相容度对类别的次序敏感，正向与反向并不相同，类别相容度矩阵由 \n",
    "FCN8结果或输入的信号统计求得。u代表两种类别的相容度，在传统potts模 \n",
    "型中y代表给相似性质的像素点对赋予不同的类别时带来的固定惩罚，此模型关 \n",
    "键问题在于对每个类别对赋予了相同的惩罚，实际上不同类别的转移惩罚有很大 \n",
    "差别。比如说，对于将人和自行车分配到相邻的点时应该具有较小的惩罚值，而 \n",
    "将天空和自行车分配到相邻点应该具有较大的惩罚。所以，从样本中得到相容度 \n",
    "信息比potts模型中直接人工设定一个固定值更为符合实际情况。类别转移操作 \n",
    "可被视为l个输入与输出节点的而且卷积核尺度为1X1的卷积操作。 \n",
    "貧w ＝\n",
    " ’启(/i)\n",
    " (3.20) \n",
    "式(3.21)代表概率整合的操作，最终概率由条件似然概率u和全局先验概 \n",
    "率A(/)相减得到，u为FCN8得到的类别概率分布，此步骤不渉及任何参数，误 \n",
    "差反传可以简单在输出误差上加上负号即可。式(3.2巧代表归一化操作，然后当 \n",
    "做下次循环的输入。注意这里减或加无区别，依赖相容度矩阵来调节具体正负。 \n",
    "27  \n",
    "包(l) ＝ u爪－A(0\n",
    " (3.21) \n",
    "q，(/)＝扛Xp煩(/))\n",
    " (3.巧 左i \n",
    "deeplab的后置CRF部分采取循环计算的方式，如下公式(3.如)到式(3.25) \n",
    "所示，为了达到全局优化的结果，不断优化目标使其趋于总体优化目标，每次计 \n",
    "算的结果会被下一次循环当作新的输入，通过不断调整平衡自身的条件似然概率 \n",
    "和考虑到周围的先验分布信息，w达到类似于全图优化的结果。 \n",
    "fsoftmax(u)，t＝ \n",
    "巧的＝\n",
    " t\n",
    " (3.23) \n",
    "扫2的＝＜＝t ＜＝t\n",
    " (3.24) \n",
    "fo，o＜＝f＜r \n",
    "＝ t\n",
    " (3.25) \n",
    "softmax主要用来在开始第一次循环时用条件似然概率u (实际上由FCN8 \n",
    "得到)来初始化输入，之后按照前面的输出变下一次的输入的计算原则，t在实 \n",
    "际操作中一般取5。乃表示式(3.1巧到式(3.2巧的一次迭代过程，y为最终输出并 \n",
    "只在最后一次循环输出。针对图像信号带来的整体概率分布，可简单的将每个节 \n",
    "点的概率分布相乘，对于最优化的类别分配，只需要计对每个节点取对应的最大 \n",
    "的输出概率类别节点即可。之所可以将整体优化的CRF过程变成分离的单个 \n",
    "节点优化相乘的形式，是因为每次迭代过程中每个节点就考虑了周围节点的影响， \n",
    "迭代过程就是在考虑周围点对该节点的最终影响，迭代次数越多，最终整体结果 \n",
    "如式(3.26)所示，得到的值就越接近全局优化下的该点分立值。 \n",
    "0的二叮公化)\n",
    " (3.26) \n",
    "3.2.2 de巧lAB模型训练 \n",
    "de巧lAB之前的一些后置CRF优化方法采用梯度下降法[67潤，而de巧lAB \n",
    "的后置CRF采用的是网格优化法，只有正向操作，没有误差反向传递过程，由 \n",
    "每个参数序列生成结果，将结果最好的参数取值保存下来即为后的CRF参数 \n",
    "不再改变，具体方法是将所有相关参数分别设定一个范围，然后选择合适的间距 \n",
    "划分网格，对所有分立值采取循环遍历的形式，选择其中对训练样本有最高的整 \n",
    "体正确率值的参数设定，并保留该参数作为CRF层的固定参数。 \n",
    "28 \n",
    "3.3基于边缘区域变换的DT网络 \n",
    "3.3.1 DT 网络 \n",
    "CNN衍生的FCN等对于场景语义分割十分有效，主要任务是对图像中的每 \n",
    "个点分配一个类别标签。最近对FCN的后处理操作如加上全连接CRF能有效改 \n",
    "善分割精度和物体边缘信息，全连接CRF的概率转移对双边滤波器的应用是对 \n",
    "边缘敏感的，对中也点距离较近化及颜色相近的转移系数较大，表示可能有相同 \n",
    "类别，实际应用过程中可以使分割结果比较符合物体的实际边缘[691。 \n",
    "为了进一步较好的改善边缘信息，在使用deeplab的CRF之前，应用DT \n",
    "算法pw的递归方程在图像行列的序列信号上，该递归方程对边缘敏感，所有扩 \n",
    "散在边缘处停止。区域变换即DT可以看做RNN网络的特例，可以方便的表示 \n",
    "为gru单元。扩散操作与边缘强度图有密切关联，在标准DT模型中边缘强度 \n",
    "由颜色梯度得到，但我们将从FCN中巧层学习得到该强度值，重要的是我们可 \n",
    "w从端对端的训练中得到内部边缘网络的卷积核权重，w得到样本相关的边缘滤 \n",
    "波器。 \n",
    "DT网络[71惭模型由h部份组成，它们首尾并接的连接在一起训练，共同优 \n",
    "化最后的分割结果的精度。第一个组件基于Vgg16[721结构的FCN8得到粗略的 \n",
    "分割预测的得分。第二个细件被称为内部边缘网络，该网络利用FCN8的中间层 \n",
    "得到的特征，这些特征层在被堆叠么前被会填充到同样的空间尺度，一个卷积核 \n",
    "为1X1尺度的只有1个输出通道的卷积层被用来作为边缘强度预测，后接上 \n",
    "RELU层用来使输出在0到1的范围。第三个组件是DT网络，这是一个保留边 \n",
    "缘信息的滤波器，通过分别在行和列上套用一维递归滤波器实现高效的操作。尽 \n",
    "管DT传统上用作普通的图像处理，我们用它来过滤粗略的FCN分割结果得分 \n",
    "使其与物体边缘结合得更好，通过内部边缘网络得到的边缘强度图。 \n",
    "3.3.2边缘区域变换算法 \n",
    "DT (区域变换)网络需要2个输入，粗略的待滤波输入信号X，在我们的案 \n",
    "例中就是FCN8得到的初步分割结果得分，另一个是正相关的区域变换转移密度 \n",
    "信号d。输出信号是滤波后信号y。对于一维的n长度信号，如式(3.27)设置义＝ \n",
    "29  \n",
    "并循环i＝2，.？n计算输出信号 \n",
    "义＝(1 － w，批 ＋\n",
    " (3.27) \n",
    "权重wi取决于区域变换密度4？表示为式(3.28)： \n",
    "wJ. ＝ eXp(－怎dJ / 〇■：)\n",
    " (3.28) \n",
    "〇■，代表空间区域的卷积核标准差，区域变换密度4决定了扩散范围，通过 \n",
    "控制X，和前一个滤波后信号义＿1的相加比例得到当前信号乂，wJ处于0到1的范 \n",
    "围，控制点i－1到i的信号传递强度，如果di十分小，我们会得到全扩散，义＝乂＿1 \n",
    "以及w，.＝l。另一个极端是4的值十分大，此时w，.＝0，扩散终止，导致义＝ \n",
    "可以见到一维信号如果只沿着一个方向如从左到右，那么下个信号将只取决 \n",
    "于前一信号，为解决此问题可以从左到右和从右到左来滤波两次。 \n",
    "对于二维信号的区域变换，在每个信号维度用一维滤波器循序的滤波，分别 \n",
    "从上到下，从下到上，从左到右，从右到左四个方向顺序滤波，之后整体进行k \n",
    "次循环来减小误差。我们减小每次循环的DT卷积核的标准差，如式(3.巧)，每 \n",
    "次第k次用〇■＆代替〇■，来计算wJ。 \n",
    "2＾－＊ \n",
    "口k 二。S术一二、…，k\n",
    " (3.29) \n",
    "V4＾－l \n",
    "区域变换密度4定义为式(3.30)； \n",
    "4＝1 ＋ ＆ 鱼\n",
    " (3.30) \n",
    "＆代表边缘强度，是边缘强度图的卷积核标准差，＆越大，代表点i越 \n",
    "可能是一个边缘点因此扩散在此终止，通用的DT网络使用颜色梯度如式(3.31)： \n",
    "＆二至11 ▽沪 ii\n",
    " (3.31) \n",
    "亡＝1 \n",
    "我们的想法是通过反向传递输出y的分割误差到两个输入，这使得我们将 \n",
    "DT转化为神经网络层，我们因此可以联合训练FCN8的粗略的分割结果X和边 \n",
    "缘强度g的相关参数。 \n",
    "我们假定每个点乂不仅影响接下来的点义＋1，还作为一个子层的输入，因此 \n",
    "反向传递时除了考虑点少41的误差反传外也接受子层的反向误差。与标准的反向 \n",
    "传播类似，我们反向递归套用式(3.32)到式(3.34)，更新参数y，w， X的相 \n",
    "30 \n",
    "应偏导数。 \n",
    "苦吟w嘴\n",
    " (3.32) \n",
    "—4＾ old (―) ＋ (—\n",
    " (3.33) dwJ dwi\n",
    " 妙i \n",
    "dl …8l、 dl \n",
    "—\n",
    "￣\n",
    "￣ 户 〇id(：＾—) ＋ wJ\n",
    " (3.34) \n",
    "如1 如 撕 \n",
    "由于权重w，在四个方向的滤波中以及k次循环中都是共享的，所以每次的 \n",
    "偏导数都应该相加作为整体。用这些偏导数我们能够得到边缘强度图的偏导 \n",
    "数，通过链式规则得到＆的偏导数如下式所示，l表示目标误差函数。 \n",
    "w， ＝eXp(－全(1 ＋ ＆ 鱼X)\n",
    " (3.35) \n",
    "口k\n",
    " 口r \n",
    "dl 來 cXg dl \n",
    "—\n",
    "二\n",
    "\n",
    "\n",
    " (3.36) \n",
    "诲 口k打r 献， \n",
    "这些偏导数之后会被传入内部边缘网络，这是用来得到边缘强度预测值的。 \n",
    "我们还可以建立与口控RNN[73毕元的联系，该RNN起初用来分类序列文本数据， \n",
    "此RNN有如下规则 \n",
    "义＝2，夾＋(1－2，此1\n",
    " (3.37) \n",
    "该式(3.37)中，Z，.＝l－w，.，yi ＝ X，.，Z，被定义为2，＝(7(乂)，乂 是激励信号， \n",
    "以及激励函数〇■的＝ l/(l ＋ e－＇)，因此可以得到DT中边缘强度图＆和激励信号乂 \n",
    "的关系如下： \n",
    "各＇＝尹思 〇g(l ＋ ＾)－l)\n",
    " (3.3 巧 \n",
    "3.4本章小结 \n",
    "本章主要介绍了传统的CRF计算过程和CRF的基本原理和传统方法块特征 \n",
    "提取的特征描述，介绍了强度，纹理，极化矩阵特征，然后介绍了基于后接全连 \n",
    "接CRF计算的原理的deep加网络，描述了全连接CRF的计算过程，最后介绍 \n",
    "DT网络的原理和其基本算法，不过其具体分析和改进留在第4章说明。 \n",
    "31  \n",
    "4 基于FCN－hed边缘和改进DT扩散模型的内部 \n",
    "与外部融合的神经网络的分割模型 \n",
    "4.1 FCN－hed边缘网络 \n",
    "4丄1 FCN－hed的结构 \n",
    "在自然图片中检测边缘和物体边界是个前沿且具有挑战的课题，这对于图像 \n",
    "处理的多个领域如图像特征，图像分割，图像检测与识别，图像跟踪与动态分析， \n",
    "医学图像检测，3d重建，等至关重要，还可以用来实现自动驾驶，提升图像语 \n",
    "文解析等现阶段应用。长期的实验证实自然图片的边缘定化由视觉感知的不同层 \n",
    "级决定[74][75]。一个相关的感知实验[76h正明不同物体确实有某种程度上的不同指 \n",
    "弓i，与其颜色上的边界和边缘的分布无关，也就是说两者实际边界间的颜色差距 \n",
    "或者特征向量差距可能很小，即梯度很小，但人眼看来可认定为强边缘，通俗 \n",
    "上说，比如一个同色圆形嵌入到两者颜色人眼刚刚能分出差别的一个同色矩形的 \n",
    "中间，单从计算上边缘颜色梯度很小但从全局上讲可以看成很强的内部圆形达缘， \n",
    "另一种情况是一个人身上有不同颜色的衣服和裤子但我们看来其整个人身体周 \n",
    "围的边缘是最显著的，之后才会注意到某个人衣服的内部分界线，而从算术意义 \n",
    "上身体周围的颜色搏度可能不如衣服和裤子或其他部位的颜色梯度大。 \n",
    "图像边缘检测有着悠久的历史，分为如下几类，第一，早期的工程学算子 \n",
    "SoBelp7l cAnny算子[78]，第二，基于特征的信息论方法，如pB[76]， gpB[79]，第 \n",
    "三基于人工特征的机器学习的如拙l[w]，Sketch tokenS[w，结构边缘法脚等。 \n",
    "除此之外，最近出现的CNN潮流强调榜征的自动提取与学习，从而产生 \n",
    "deepedget831，cSCNNt843等wCNN为基础的边缘提取方法。就目前来说，结构 \n",
    "迈缘法有着目前综合上最好的效果。CNN的方法也有较大提升空间。 \n",
    "FCN－hed[85骑应于对应于FCN网络，五个尺度的内部层分别后接对应尺度 \n",
    "的反卷积层恢复到原图大小输出五个内部边缘层，结合所有五个边缘层后接卷积 \n",
    "层输出化Se层，然后每个边缘层和fuSe层采取联合优化，权重都设为1，边缘层 \n",
    "和fuSe层都统一依照边缘gt图进行训练。 \n",
    "为了检测边缘采用了 一个端对端的边缘检测系统，命名为整体嵌套边缘检测 \n",
    "32 \n",
    "网络(肥0)。依靠卷积核的权重更新，它可1＾＞1自动学习丰富的层次特征，决定该 \n",
    "特征是否重要对于模拟人的视觉来解决物体边界和边缘的抽象性。 \n",
    "虽然没有湿式的结构性针对边缘检测输出建模，并没有向传统方法那挣特地 \n",
    "寻求计算梯度值来比较！＾＞1分辨是不是边缘，整体的意思是利用61边缘图进行图 \n",
    "对图的训练与预测。嵌套的意思是强调继承和提炼内部边缘图，通过综合所有的 \n",
    "边缘输出可以得到更加精确的边缘预测。这种完整的基于多层次的可学习的特征 \n",
    "架构比往的多尺度方法一是特征是学习出来的而不需要人为设定特征 \n",
    "提取方式，二是多层次之间存在直接联系而不是分立存在。 \n",
    "hed主要着重于解决两个关键问题，1)整体的图像训练和预测，基于FCN \n",
    "网络，进行图对图的分类，输入为完整的彩色图，输出为边缘强度图。2)嵌套 \n",
    "的多层次特征学习，基于FCN的多层次结构决定，将所有5个尺度的持征层都作 \n",
    "为内部边缘层产生边缘，再后接一个反卷积层恢复尺度。 \n",
    "一系列卷积，池化，陆lu操作 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  i\n",
    " －\n",
    "－\n",
    " 气 \n",
    "原图 i原图尺度/2 原图尺度/4 原图尺度/8 原图尺度八6原图尺度/32 \n",
    "n反卷积X2 n反卷积X4 ＆反卷积X8 n反卷税AS。反卷积X32 \n",
    "目标 \n",
    "/\n",
    "—\n",
    "—\n",
    "\n",
    "\n",
    "＼(  \n",
    "边缘强度标注图原图尺度 原图尺度 ip图尺度 原图尺度 原图尺度 \n",
    "加权融爸 \n",
    "V \n",
    "目标 \n",
    "/\n",
    "\n",
    " \n",
    "\n",
    "＾\n",
    "\n",
    " \n",
    "\n",
    "边缘强度标注图 原图尺度 \n",
    "图4.1 FCN－hed结构图 \n",
    "4丄2 FCN－hed的计算过程 \n",
    "我们表示输入数据集通过S＝{ on，於)，n＝l，...，n}，样本 \n",
    "义\n",
    "。\n",
    "＝皆＞，？/？二 义？ 1}表示输入图像，以及 y？ ＝ {乂.＂＞，＞ ＝ 《，｜}，乂。＞ e {0，1} \n",
    "33  \n",
    "表示相应的边缘二进制标签对应于图片X。，我们的目标是建立一个网络去学习 \n",
    "特征来产生边缘强度分布通过给出的边缘分布gt图。如式(4.1)，我们简化的 \n",
    "表示所有的标准卷积层参数为w，假设每个网络有M个内部边缘输出层，每个 \n",
    "内部输出层与一个分类器相连，相应的权重表示为w二批，则目标函 \n",
    "数为 \n",
    "l\n",
    "咖所您(w，w(M))\n",
    " (4.1) \n",
    "M＝l \n",
    "如式(4.2)，表示每个内部输出层图像级别的损失函数，训练时损失函 \n",
    "数计算图像的每个点的损失，对于通常的自然图像，边缘点的数量远小于非边缘 \n",
    "点，故我们采取一个简单的策略去平衡正负样本的损失问题。我们引入一个正负 \n",
    "样本平衡参数目基于边缘点和非边缘点的比例，J是图像X的像素点空间索引。 \n",
    "我们依靠调节参数目来消除正负样本数量的不平衡，定义如下的基于类别的损失 \n",
    "函数 \n",
    "您(w，w＂)二－声完 logpr的二 11 义爪 w(M)) \n",
    "？ 卿\n",
    " (4.2) \n",
    "－(1 －公)X logpr化＝01 义；w，w(M)) \n",
    "在这里向＝｜7 ｜/｜；n，l－＾＝｜r＋｜/｜y｜，pr化＝＾尤爪八＂))二叫聲))￡化口， \n",
    "通过Sigmoid激活函数〇0计算点J的值，每个内部输出层，我们得到边缘强度 \n",
    "祗＞ (也])，这里省＝{沪，？/二是内部输出层M的输出值。 \n",
    "为了直接利用内部输出层，我们添加了加权融合层，每个加权值由网络训练 \n",
    "得到，融合层的损失函数如下式(4.3)： \n",
    "正\n",
    "知(w，w，A)＝旅伴知\n",
    " (4马 \n",
    "这里爲)，＆ ＝脚，…，/＾)是融合权重。diSt是饥图和融合层 \n",
    "预测图的距离函数，将上述结合，我们选择最小化如下式(4.4)的目标函数通 \n",
    "过标准梯度下降法。 \n",
    "(w，w，/i)＊ ＝ 0[巧 Min(王加e(w，w) ＋ 王如(w，w，A))\n",
    " (4.4) \n",
    "内部输出层插入在卷积层之后，每个内部输出层对应同一个gt图以使得它 \n",
    "们得到我们想要的输出，网络的输出是多尺度的，具有不同尺度的感受野和特征 \n",
    "34 \n",
    "输出图，越深层次感受野变大特征输出图变小，融合层被添加进网络，融合不同 \n",
    "尺度内部输出的权重也是网络学习到的，整个网络由多个多尺度的误差反传通道 \n",
    "来训练的。 \n",
    "假设输入图像X，我们可同时得到其内部输出和融合层输出，最终的结果 \n",
    "是这些层输出结果的平均值如下式(4.5)，分别有融合层和五个Side层平巧后输 \n",
    "出。 \n",
    "t＾ ＝ AVerAge(f批，专訟，…，邀))\n",
    " (4句 \n",
    "4.2传统彩图边缘检测方法 \n",
    "由于边缘检测的方法很多，各种方法的原理不尽相同，都有与梯度高度相关 \n",
    "且无层次性无大局观的特点，这里主要介绍基于颜色向量距离的梯度方法，其中 \n",
    "典型的如SoBel算子在边缘检测领域方面具有举足捏重的地位。他主要基于图像 \n",
    "信号的一阶梯度，用于提取简单的边缘和物体分界线。通过得到在水平和垂直方 \n",
    "向的梯度分量并得到其合向量的幅度和方向来确定边缘，并且需要设定阔值来确 \n",
    "定是否显著性边缘，实际计算是卷积两个方向的相应卷积核即可，具体计算过程 \n",
    "不再叙述。 \n",
    "SoBel算子用于快速提取边缘，只需在图像上套用卷积核遍历一遍即可，简 \n",
    "单快捷。由于该算子仅仅根据像素间的梯度分布来决定边缘强度，而忽略了主体 \n",
    "与背景，及各宏观物体的边界，人眼识别物体边缘时具有抽象整个物体的能为， \n",
    "使得不同物体的分界线格外明显，这不是单单梯度就能解决的问题，这也是传统 \n",
    "边缘提取方法的通病。 \n",
    "然而对于彩色图像具有三个通道的RGB值，当然可以分成三个单通道灰度 \n",
    "图像进行单独的梯度提取后取平方和后归一化合并成单个的梯度值。但是这与在 \n",
    "RGB空间中直接计算梯度并不完全一样，考虑到平面上一点到另外一点的颜色 \n",
    "向量的改变＞ 考虑式(4.6)和式(4.7)，假设r，g， B为巧B空间的单位向量， \n",
    "那么对于平面的X，y方向有如下的公式，u，V分别是在X，y方向上颜色空间的相 \n",
    "应梯度； \n",
    "dr 8g 8B， \n",
    "＂二\n",
    "石＂芯《＋志6\n",
    " (4.6) \n",
    "35  \n",
    "d民 dg dB l \n",
    "V二\n",
    "贡r ＋亦《＋亦6\n",
    " (4.7) \n",
    "最关键的是如何确定平面的梯度方向，使其在颜色空间中有最大的合成梯度 \n",
    "值，根据定义，假设该角度为0，那么该问题等价于优化下式(4.8)，u代表X \n",
    "轴颜色空间向量，V代表y轴颜色空间向量： \n",
    "ArgMAX。i McoS0 ＋ VSin0p\n",
    " (4.8) \n",
    "具体计算过程不再叙述，通过上式可得到如下式(4.9)的角度值，注意 \n",
    "单纯用该式如果不再去计算u和V的正负关系去确定求得的是需要优化的西数的 \n",
    "最大还是最小值的话，那么该角度值需要加减90度后再计算一次梯度值，比较 \n",
    "两者谁大谁小，注意必有一个最小值和最大值。由于0与0 ＋ n等具有相同的梯 \n",
    "度值，故最终的计算范围限定在0到180度即可。 \n",
    "6＝0.5＊tAn—乂 ＾＾2)\n",
    " (4.9) \n",
    "u —V \n",
    "4.3融合方法和改进的DT扩散模型 \n",
    "上述得到的谊缘强度图需要预处理，主要是阔值的选择和边缘的细化次数， \n",
    "阔值选择过低会导致迪缘过多，一些强度低置信度低的近缘会对融合结果产生负 \n",
    "面影响，阔值选择过高会丢失边缘信息导致对融合结果没影响，选缘细化次数过 \n",
    "大会导致只边缘过细，实际运用过程中与实际边缘有一定偏移会导致较大误差， \n",
    "细化过低会导致边缘线条过粗，这样对融合结果改进较小也不合适。在样本训练 \n",
    "时通过最后融合时的参数选择确定最好的参数，发现细化次数为2和阔值取约 \n",
    "0.4时对于每个训练样本都有比较好的效果，实际在最终测试时对于测试图片也 \n",
    "有最好的效果，可[＾在之后的参数曲线图中证实。 \n",
    "DT网络存在的问题使得DT网络的效果多数情况下改进不大，主要存在(＾＞1 \n",
    "下关键问题； \n",
    "1，由于采用内部边缘网路隐式产生边缘强度，对于复杂的环境这样的边缘产生 \n",
    "方法十分不精确，需要显式的边缘网络。 \n",
    "2，有些不同类别相交处的边缘颜色梯度可能不大，这样直接套用扩散方程会抹 \n",
    "掉这些区域变成同一类别，会带来极大误差。 \n",
    "3，扩散应该是向着最近的边缘方向正向扩散的，逆向的扩散只会使错误类别扩 \n",
    "36 \n",
    "散出去从而增加误差。 \n",
    "4，针对同一类别颜色梯度可能很大，不同类别颜色梯度可能很小的情况，分别 \n",
    "对应假边缘和漏掉的边缘，假边缘会使得扩散的不彻底，漏掉的边缘会同一 \n",
    "化本来就不同类别的区域产生较大误差。 \n",
    "针对w上问题，提出改进方法原理如下： \n",
    "1，引入FCN－hed显式得到较为真实反映不同类别连接处边缘强度的图像。 \n",
    "2，引入边缘距离图变成等高线图得到扩散方向，即向着山峰的方向扩散。 \n",
    "3，远离显著边缘的区域类别分布与颜色梯度的直接关系减弱，并且扩散方向难 \n",
    "w确定，所以扩散限定只在显著边缘附近操作。 \n",
    "4，两邻接点间颜色向量差距和初始类别概率分布向量差距所带来的扩散系数 \n",
    "的变化分别由两个参数调节，w适应颜色差距大而类别一样或者颜色差距小而类 \n",
    "别不同的问题。 \n",
    "A V B \n",
    "f \n",
    "图4.2扩散方向的选定示意图 \n",
    "如图4.2，虚线表示真实的边界，实线表示实验分割结果的类别边界，是A与B \n",
    "区域之间的分界线，假设箭头代表扩散法的扩散方向，注意到对于分割结果的两 \n",
    "区域边界，扩散方向始终指向虚线，上面由A扩散向B，下面的由B扩散向A， \n",
    "观察可知，扩散方向满足由边缘距离较远的向边缘距离较近的箭头指向，实际某 \n",
    "点的边缘距离是该点到最近的边缘线的最近距离来衡量。 \n",
    "4.3.1外部融合和改进DT扩散法 \n",
    "己知道边缘分布和分割结果，而边缘分布又不完全可信，以及部分边缘可能 \n",
    "丢失，借鉴DT中四方向扩散的思想，化及边缘距离图作为扩散参考，采取强约 \n",
    "束条件和符合实际场景的判断方法，得到如下算法 \n",
    "37  \n",
    "1)改进DT扩散法 \n",
    "1，选择合适的边缘细化次数和阔值二值化，得到新的边缘分布图和相应的 \n",
    "边缘距离图，计算方式如式(4.10) ， 表示距离，Min表示取极小，；f(w，打) \n",
    "表示边缘点，表示最小边缘距离。 \n",
    "AJ\n",
    " J)，(w，n)))，/or；r(w，n) e f＋\n",
    " (4.10) \n",
    "2，确定迭代次数t，每次迭代时分别有从上到下，从左到右，从右到左， \n",
    "从下到上依次四个方向进行如下扩散操作，如式(4.11)和(4.12)，此时w，由 \n",
    "颜色向量差别和类别概率向量差别及其分别对应的系数控制。i表示像素点的 \n",
    "RGB颜色向量，p表示像素点类别概率分布向量与X向量含义一样，扩散系数 \n",
    "具体强度由0巧制，分别取1和1/200比较合适。 \n",
    "y， ＝。－ w 批＋w，乂\n",
    " (4.11) \n",
    "w， ＝ eXp( i 心＋1)：严y－wJ 哗例；产，y－i)｜2) (4.巧 白1\n",
    " 6＞2 \n",
    "3，对于每个方向的扩散，有如下的先决条件，若不满足则需要维续到下一行 \n",
    "或者列开始扩散。 \n",
    "Xi－i\n",
    " Xi \n",
    "f f 1－wi \n",
    "yi－i\n",
    " yi \n",
    "图4.3扩散方程不意图 \n",
    "4，比如对于由左向右扩散，首先必须是边缘附近但不能是边缘点，满足0＜ \n",
    "公化y)＜A，一般取A为0.35，还必须统计到该点之前属于该点类别的近邻连续统 \n",
    "计的点的数量之和，当该数量超过一定数量，我们才认为该点属于有效区域。 \n",
    "5，接着比较公Ay－1)和公(u＋1)的大小，如式(4.13)如果 \n",
    "。片1)－公化＿/ ＋ 1)＞0，即扩散势大于0，而且y(i说日y(iJ＋1)的类别不同则表 \n",
    "明扩散是向着边缘的满足扩散方向条件。 \n",
    "38 基于贝叶斯框架的全卷积网络和思式边缘网络修正的SAR图像分类 \n",
    "Vd ＝ Z)化 7.—1)—公0，7 ＋1) ＞ 0 \n",
    "A n\n",
    " (4.13) q ＜ dJ J ＜ A \n",
    "6，除了上述约束外，考虑到边缘的不准确性，还需要添加一个重要的条件， \n",
    "当满足5之前的条件后记录y(i，J＋1)的类别，继续延长J的大小直到遇到第一个 \n",
    "边缘点，然后继续延长直到脱离边缘区域后遇到的的第一个点设为y(lJJ)，如果 \n",
    "y(iJ＋1)和巧iJJ)的类别相同，我们才有理由认为点〇J＋l)所属区域是点0如突破 \n",
    "边界延展来的，属于错误分割结果，才能决定可以扩散。 \n",
    "7，如果6的条件不满足，说明点和点iJ＋1之间可能也存在边缘线，只 \n",
    "是边缘分布图漏掉了这些边缘，那么点iJ和点u＋1之间由于实际可能之间有边 \n",
    "缘存在就不能进行扩散操作。所有条件如果满足，就设定y(iJ＋1)的类别为y(iJ) \n",
    "的类别然后继续扩散。 \n",
    "边缘约巧 \n",
    "边缘图 0 \n",
    " 5\n",
    "\n",
    " \n",
    "\n",
    "哀 ＆ 口 。f i ？ ？ レ以心以 \n",
    "5\n",
    " 1\n",
    "  1 i 5 \n",
    "  循环计算\n",
    "\n",
    " \n",
    "\n",
    "图4.4 DT四方向扩散原理图 \n",
    "8，当所有4个方向完成扩散之后，将当前结果重复步骤2之后的操作直到 \n",
    "到达t次迭代之后停止，一般取t＝5或10。 \n",
    "2)补洞法 \n",
    "1，扩散法后可能留有一些小的空洞，可采用一些带有强约束的区域填充方法 \n",
    "来填充空洞。 \n",
    "2，策略是在边缘附近遍历每一个非边缘点，由该非边缘点确定一个10＊10 \n",
    "选定范围的区域，w该区域的边和区域中的边缘点为边界，可将该区域分为很 \n",
    "多小区域。 \n",
    "3，选中包含该中也点的小区域，统计其中占比最多的类别，如果占比超过 \n",
    "39  \n",
    "90％t＾Jl上，则设定该区域所有点的类别为该类别。 \n",
    "4.3.2改进DT扩散模型的训练 \n",
    "两参数训练采用梯度下降法，具体梯度公式如式(4.14)所示，假设g巧代 \n",
    "表i处是否在DT扩散法中进行过扩散，1代表扩散过，0则相反。l表示目标函 \n",
    "数，代表当前乂和真实义的差值，表示当前乂的梯度，new？＾表示实际 \n",
    "喊\n",
    " 诚 \n",
    "梯度计算时更新的y，的梯度。由式(4.15)可知，i与i＋1的梯度有关，故实际 \n",
    "运算时需要反向运算，一般序号由n到1进行反向传播计算。将所有的y的梯度 \n",
    "更新完毕后，便可以求得参数w的梯度进而累加得到9的梯度值。 \n",
    "一 \n",
    "—\n",
    " —\n",
    " 一 \n",
    "8l\n",
    " 化 ＊ 9方\n",
    " ＊ 从＿， － X，)，g〇.) ＝ 1 \n",
    "— ＝ new＾＝＾＊＾ ＝ ＜ 5 乂\n",
    " (4.14) \n",
    "owi\n",
    " dV ow. ，\n",
    " 少＇\n",
    " ，\n",
    " 0，g(〇 ＝ 0 \n",
    "在式(4.15)中，g (i)代表i点是否扩散过，w为扩散度，old代表下层直 \n",
    "接传来的误差，new代表更新后的误差，l表示目标误差函.数。 \n",
    "old＾＾ ＋ new ■ ＊ w，＇＋i，g闲＝1 \n",
    "目l\n",
    " 喊 邸＋1 \n",
    "new\n",
    "＾ ＝ ＼\n",
    " [■\n",
    " (4.15) \n",
    "喊\n",
    " old 聖，g(i) ＝ q [ 如\n",
    " J \n",
    "如式(4.16)和式(4.17)，6，和0。是扩散參数，i表示颜色向量，p表示类 \n",
    "别概率向量，i和J代表位置，参数更新公式如下。 \n",
    "覃二？贵赛＝罕赛心＋V？’片)＇2 (＂6) \n",
    "豈＝？贵赛＝罕贵心(＂7) \n",
    "43.3内部融合 \n",
    "DT中的内部边缘网络采取隐式得到边缘的方法，即训练样本中只有分割gt \n",
    "图作为参考，边缘是由训练时隐式产生的，没有边缘的gt图，这样可能产生出 \n",
    "不稳定不精确的边缘所以我们引入FCN－hed的边缘加权与DT的内部边缘相加， \n",
    "实际加权系数由网络則练得到，一般来说通常初始化为化5。 \n",
    "40 \n",
    "1) FCN－hed边缘与DT的结合 \n",
    "通过结合FCN－hed得到的边缘与DT中的内部边缘网络得到的＆可以得到 \n",
    "下式，如式(4.18)，A为分配权重，取值的范围从0到1，为新的DT的输 \n",
    "入，代表着该点边缘强度的幅值大小。 \n",
    "＆\n",
    "｜ ＝ A＆＋(l－的各产－kd\n",
    " (4.18) \n",
    "如式(4.18)中的Si都被＆＇代替，由链式规则计算偏导数，则真正传到＆的 \n",
    "误差为式(4.19)，A为分配权重，l为目标函数。 \n",
    "Bl 8l ＊ \n",
    "＾ ＝六 A\n",
    " (4.19) \n",
    "婚始＇ \n",
    "FCN－hed的参数固定不更新，采取固定FCN－hed输入的方法，而 \n",
    "参数A的更新公式为式(4.20)，由于A对于所有点的加权系数是共享的，所 \n",
    "应该进行叠加，l为目标函数。 \n",
    "真＝共＊(各，－护－祭\n",
    " (4.20) dA 墙＇\n",
    " dA \n",
    "在神经网络中，可等效如下式(4.21)，此时A可取0到正无穷，此时巧始化 \n",
    "为1，可由一个单通道1X1卷积核的卷积层和一个Add操作的BitwiSe层＾及一 \n",
    "个RELU层完成上述等效运算。实践应用中的参数优化过程则由网络梯度下降 \n",
    "法以及误差反传得到。 \n",
    "＆\n",
    "｜ ＝ RELU(A＆ ＋ ＆脚－始d)\n",
    " (饲 \n",
    "41  \n",
    "4.4完整结构 \n",
    "i\n",
    " ＿ 1 ＿ \n",
    "c？？rrS8M＞ \n",
    "图4.5完整流程图 \n",
    "完整流程如图所示，首先训练FCN8网络得到初步的FCN8模型，然后在 \n",
    "FCN8后加上deepl油的CRF部分网络，载入刚才得到的FCN8模型，网格优化 \n",
    "法得到deeplab的CRF部分的合适参数，这个参数将一直使用，然后将DT加在 \n",
    "FCN8后，deeplab的CRF部分在DT后，载入FCN8模型进行微调得SJDT模 \n",
    "型。接着用FCN－hed得到每个样本的边缘图及对应的边缘距离图，将样本边缘 \n",
    "图与巧部边缘网络加权相加并输入DT中，载入DT模型进行微调得到新的 \n",
    "FCN－hed＋DT模型，利用上述模型后接deepl油的CRF部分得到新的结果并与 \n",
    "FCN－hed边缘再进行一次外部融合得到最终结果。 \n",
    "具体数据输入流程为原始图像经过FCN8计算后会生成与原始图像同尺寸 \n",
    "的通道数为类别数的概率分布图，每个像素点输出各个类别的归一化概率。同时 \n",
    "还会利用FCN8的特征提取层接一个内部边缘网络生成边缘强度图，并与 \n",
    "FCN－hed显式得到的边缘强度图融合，通过输入DT网络修整远缘处的类别概 \n",
    "率分布。之后利用deeplab的CRF部分考虑周围区域的先验信息来进一步优化 \n",
    "各个像素点的类别概率输出，最后融合FCN－hed生成的边缘图，当然还需要边 \n",
    "缘距离提供参考，显式的进行全局的边缘周围范围的联合优化，达到一个适中的 \n",
    "效果化及良好的边缘分布图像。 \n",
    "42 \n",
    "4.5本章小结 \n",
    "本章首先介绍了最新的FCN－hed这种专门提取边缘的网络和他的结构，并 \n",
    "分析了与传统方法的显著优势，然后重点分析了DT网络的各种显著的缺陷，并 \n",
    "一\n",
    "一进行改进，得到了自己改进的DT扩散模型，应用迄种扩散方法和其他的小 \n",
    "技巧，以及FCN－hed显式得到的边缘，进行外部和内部的融合方法，最后得到 \n",
    "最终的整体的完整结构。 \n",
    "43 武没大学硕±论文 \n",
    "5 实验结果与分析 \n",
    "5.1实验数据与步骤 \n",
    "本文SAR图像为德国某处的ESAR图像，如固5.1所示，原图尺寸口00X1100， \n",
    "为了方便FCN8网络的50化500的输入尺度，故将大小截取为100化1000像素， \n",
    "经过了 pAuh伪彩图化处理，其中感兴趣的区域分为5类，分别为耕地，建筑、 \n",
    "林地、道路和其他陆地覆盖物，标注图如图5.4中gt图所示。实验采取linuX \n",
    "下的cAffe平台，其中FCN基于Vggnet的初始模型。 \n",
    "M \n",
    "图5.1 ESAR数据图 \n",
    "SAR数据中每种类别的标注颜色统一由表1给出。由于FCN输入为50化500， \n",
    "44 基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR围像分类 \n",
    "而且训练时用到了所有的点的信息，故采用拆分测试法将大图平均分成共四块测 \n",
    "试图，然后w每隔100个像素单位4个方向进行滑动，则可以得到包括测试图共 \n",
    "20张图，每次试验取4幅测试图当中的一幅图片用来测试，然后训练时取剩下 \n",
    "19张图片中的11幅与测试图片无任何像素点有交集的图片，故共进行四次大的 \n",
    "训练得到相近的4个模型和对应的测试图片结果，最后合并4张测试图片结果得 \n",
    "到最终的大图测试结果，在保持得到方法的真实正确率情况下也充分利用了原来 \n",
    "的图片资源。传统实验先用meanshift得到粗分割像素块，针对每块提取部分强 \n",
    "度特征、纹理特征和极化分解特征即文献[90]所采用的像素块特征，用SVM直 \n",
    "接分类或者用基于potts先验的CRFpw引入邻域信息来综合分类，训练与测试 \n",
    "样本设置方法与FCN等一致。 \n",
    "表1本文SAR数据的真实地物目标标注颜色 \n",
    "类别 建筑\n",
    " 林地\n",
    " 耕地\n",
    " 道路\n",
    " 背景 \n",
    "颜色 — — — — iM \n",
    "5.2实验设置 \n",
    "为了测试改进方法与原方法在实际SAR图像分割上的优劣和效果，本文在 \n",
    "ESAR数据上进行7组实验，某中传统方法所需要的的块特征包括16维灰度直 \n",
    "方图、7维hAAr特征、17维商斯纹理滤波器组特征、9维极化分解特征(3维 \n",
    "Pauli分解、3维Sdh分解、3维huynen分解)，－义：49维特征。 \n",
    "1，实驗一！基于meanshift分觀和po化先验的CRF分类方法 \n",
    "本文使用主流的过分割meanshift算法对实验数拋进行分块，设凰最小块大 \n",
    "小为200，得到ESAR数据的过分割块数目为3370。巧超像素块上提取特征，实\n",
    " ， \n",
    "验分四次，具体样本设置如上面所述，每次得到一个部分的结果，共得到4块后 \n",
    "最后拼成大图。 \n",
    "2，实验二：基于meanshift分割和SVM的国像分类方法 \n",
    "本实验与实验＾设置一致，训练和测试方法也一样，只是分类器由〇1？变 \n",
    "成区域间无关连的单纯SVM分类器。 \n",
    "3，实验h：基于FCN8的图像分类方法 \n",
    "45 ？ ＿ iS没大学硕±论文 \n",
    "直接基于样本和对应的类别标注图，利用FCN8网络训练得到初始结果和 \n",
    "FCN8模型。 \n",
    "4，实验四：基于FCN8＋d说plab團像分类方法 \n",
    "实验设置同h，载入FCN8模型，并用deeplab的CRF部分作为后畳优化 \n",
    "实验结果。 \n",
    "5，实验五：基于FCN8＋DT＋deeplab的困像分类方法 \n",
    "实验设置同h，载入FCN8模型，将DT移植进FCN8网络中训练得到 \n",
    "FCN8＋DT模型，并用deeplab的CRF部分作为后置优化实验结果。 \n",
    "6，实验六：基于FCN8＋FCN－hed＋DT＋deeplab的图像分类方法 \n",
    "实验设置同h，载入FCN8模型，将DT移植进FCN8网络中训练得到 \n",
    "FCN8＋DT模型，利用FCN边缘网络得到边缘分布图，与DT的内部边缘网络输 \n",
    "化融合后输入DT中，并用deeplab的CRF部分作为后置优化实验结果。 \n",
    "7， ＾＾毛：基于 FCN8 ＋ FCN－hed＋DT＋deeplab＋FCN边缘网络后：＆规合 \n",
    "的围像分类方法 \n",
    "实验设置同h，载入FCN8＋DT模型，并用deepl沈作为后置优化实验结果， \n",
    "利用FCN边缘网络得到边缘分布和边缘距离图，分别与DT的内部边缘网络输 \n",
    "出融合后输入DT中，然后结合deepBB的CRF部分的结果利用改进DT扩散法 \n",
    "和补洞法进行融合得到最终结果。 \n",
    "46 基于贝叶斯框架的全卷积网巧和晶式边缘网络修正的SAR图像分类 \n",
    "5.3实验结果\n",
    " ？ \n",
    "1，下面是FCN－hed网络得到的边缘和对应的边缘距离。 \n",
    "圓圓 边绿分布\n",
    " 边绿距离 \n",
    "图5.2边缘图相关结果 \n",
    "2，下面是某一种扩散参数下的边缘的细化次数和取思著边缘的阔值设定， \n",
    "通过具体实验可知阔值取0.4 以及细化次数取2比较合适。 \n",
    "化｜—爾值为ol＂ 爾值为03 \n",
    "0＿8 口－\n",
    " i 爾值为04 \n",
    "＇ 聞值为05 \n",
    "0.808 －\n",
    " ＂＂ \n",
    "0 807＇\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 1\n",
    " 、\n",
    " 1\n",
    " ？ \n",
    "123456789 10 \n",
    "边巧细化次巧 \n",
    "图5.3参数曲线图 \n",
    "3，下面是各种实验的具体结果图像 \n",
    "47 武没大学硕±论文 \n",
    "M M \n",
    "pf 闘圍 SVM\n",
    " FCN8 \n",
    "p＂＊＇w tftlw \n",
    "Mp＾ MM＾ \n",
    "deeplab\n",
    " DT＿de巧lAB \n",
    "pipkJipii＾ pViqher \n",
    "Mp＾ kkS \n",
    "DT内部修正－deeplab\n",
    " DT内部修正－deeplab外部边缘修正 \n",
    "48 \n",
    "困5.4实验结果图 \n",
    "4，下面是各组实验的混淆矩阵，单位是百分比，分别提供整体正确率和各 \n",
    "类别正确率的信息。 \n",
    "＾\n",
    "\n",
    "表2 文所有实验结果的y淆矩阵＾整体正确率 \n",
    "\n",
    " \n",
    "\n",
    "分类方法 类别 建筑 林地 耕地 道路 背景 全图整体正确率 \n",
    "建筑 75.20 8.54 0.43 8.34 7.49 \n",
    "实验＿ ：\n",
    " 林地 10.20 72.97 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "—\n",
    " 2.11 6.48 8.24 \n",
    "￣\n",
    "\n",
    "\n",
    "Mew＊化＋p〇ttf 許耕地 0.92 24.02 — 2＾36 0.32 48.38— 7〇＇：33 验的 CRF 分类方法道路 6.97 4.69 ￣ 1.10 ￣58.46 28.7￣J￣ \n",
    "  背景 3.1＾\n",
    "￣\n",
    " 2.3 已\n",
    "－\n",
    "5.44 \n",
    "￣\n",
    "1.62 77.42\n",
    "—\n",
    "\n",
    " \n",
    "\n",
    "建筑 74.3\n",
    "￣\n",
    "＾ 8.1已 \n",
    "￣\n",
    " 1.14 \n",
    "—\n",
    "5.89 10.47 \n",
    "实验二： 林地 10.巧 64.的\n",
    "￣\n",
    " 13.巧\n",
    "￣\n",
    "2.73 8.26 \n",
    "M朗n＊化＋SVM 分耕地 1.1＾\n",
    "￣\n",
    " 27.74 \n",
    "￣\n",
    " 26.04 \n",
    "—\n",
    "2.47 42.60\n",
    " 66.：32 \n",
    "类方法\n",
    " 道路 8.5＾\n",
    "￣\n",
    " 5.04 4.74 \n",
    "￣\n",
    "57.12 24.51 \n",
    "  背景 5.2＾\n",
    "￣\n",
    " 3.12 8.16 10.80 72.的 \n",
    "\n",
    " \n",
    "\n",
    "建筑 94.0\n",
    "￣\n",
    " 1.24 0.2 1.55 2.96 \n",
    "￣\n",
    "\n",
    "\n",
    "18.12 71.47 \n",
    "￣\n",
    "1.26 2.77\n",
    "—\n",
    " 6.37 \n",
    "实验三：：忙n8 耕地 3.55\n",
    "￣\n",
    " 12J9 \n",
    "￣\n",
    " 已1.34 \n",
    "￣\n",
    "＾.16 25.61\n",
    " 巧.30 \n",
    "10.26 2.7已 \n",
    "￣\n",
    " 0.6 61.11 2529 \n",
    "  背景 5.18 1.51 0.68 \n",
    "￣\n",
    "17 86.45 \n",
    "\n",
    " \n",
    "\n",
    "建筑 95.3f\n",
    "￣\n",
    " 0.67 \n",
    "￣\n",
    " 0.21 0.77 2.9\n",
    "￣\n",
    "\n",
    "\n",
    "林地\n",
    "￣\n",
    "￣\n",
    "1＾33 74.57 0＾ 123 5.61 \n",
    "一、：。l 耕地 2.29 16.42 48.44 3.02 29.83\n",
    " 80.85 \n",
    "道路 11.57 3.43 0.44 已 3.巧 31.30 \n",
    "  背景 5.25\n",
    "￣\n",
    " 1.17 0.16 2.68 90.79\n",
    "—\n",
    "\n",
    " \n",
    "\n",
    "建筑 95.32 0.70 0.28 0.84 2.86 \n",
    "18.25 74.85 0.20 1.31 5.40 \n",
    "实验五：\n",
    " 耕地 2.24 17.33 47.92 ＾.12 29.39\n",
    "—\n",
    " 卵 g。 FCN8－DT＋deeplab 道路 iiSt＂ 3.50 0.44 55.07 29.42— \n",
    "J\n",
    "目\n",
    "B 景 5.28 1.23 0.16 2.91 90.42 \n",
    "建筑 95.41\n",
    "￣\n",
    " 0.70 0.19 \n",
    "￣\n",
    "0.84 2.8已 \n",
    "￣￣ \n",
    "实验六： 林地 18.25 74.85 0.20 l.St\n",
    "＂\n",
    " 5.40 \n",
    "FCN8－DT 内部边缘耕地 2.2广 17.：33 47.％ 3.1＾ 29.39\n",
    " 80.94 \n",
    "修正＋deeplab 道路 1157\n",
    "￣\n",
    " 3.50 0.44 55.07 2江 42\n",
    "—\n",
    "\n",
    "\n",
    "  背景 5.2＾\n",
    "￣\n",
    " 1.23 0.16 2.91 90.42 \n",
    "\n",
    " \n",
    "\n",
    "实验亡： 建筑 95.9\n",
    "￣\n",
    " 0.77 0.18 0.＾ 2.21 \n",
    "FCN8－DT 内部边缘林地 18.03 75.46 0.23 1.20 5.09 \n",
    "修正＋deeplab＋外耕地 2.21 16.84 49.33 3.巧 巧.08 81.巧 \n",
    "部边缘修正 道路 11.2厂 3.45 0.51 已6.7言\n",
    "￣\n",
    " 28.02 \n",
    "背景 4.98 1.14 0.16 3.46 90.27 \n",
    "49 武没大学硕±论文 \n",
    "5，下表是单独边缘区域改进率 \n",
    "表3本文边缘区域改进率 \n",
    "流 1边缘区域总点数\n",
    "￣\n",
    "￣\n",
    "i改进的边缘点数 Mi \n",
    "DT\n",
    " 25676\n",
    " 而\n",
    " 0＾ \n",
    "外部扩散法＋显7 \n",
    "25676\n",
    " 1125\n",
    " 4.4％ \n",
    "式边缘约束 \n",
    "5.4实验结果分析 \n",
    "首先对比传统的块特征提取加分类器的思路，选择SVM和CRF两种分类器， \n",
    "CRF使用logiStic分类器作为似然项，potts模型作为其先验项，FCN8较上面的 \n",
    "方法就有很大提升，至少提高了 9％w上，主要是FCN8适合围像信号和分类精 \n",
    "度较高的原因。deeplab相当于在：FCN8后接上了 CRF后处理，引入了周围像素 \n",
    "的分类信息作为参考进一步提高了分类正确率。之后在FCN8后接上了 DT网络 \n",
    "修正了边缘，但提升不是很明显，正确率和实际图像都没有显著提升。通过引入 \n",
    "FCN－hed得到的边缘与DT的内部边缘网络得到的边缘加权输入到DT中训练， \n",
    "正确率也没有很大提升，主要是DT方法本身存在很多未解决的问题以及实际画 \n",
    "像类别分布的复杂性。最后经过DT－deeplab处理后，融合前的所有方法，与 \n",
    "FCN－hed得到的结果再进行外部的边缘融合，采取含参数改进DT扩散法和补 \n",
    "洞法，正确率又有显著提升，总体也提高了 0.45％，而且各种类别的单类别正确 \n",
    "率也有一定的提升，其中非背景类别得到了明显改善，部分边缘得到修正也比较 \n",
    "贴合实际情况，仅考虑边缘区域的话正确率提商了 4.4％，这对于仅用边缘修正 \n",
    "和对比原来的DT方法来说是个很大的提升，部分边缘区域的像素也比以前更符 \n",
    "合实际的类别，总体效果得到了一定的修正。 \n",
    "通过对比原gt图和DT－deeplab 1＾1及最终的边缘修正图，如图5.5中的黑色 \n",
    "圆圈标注的所示和图5.6的部分放大对比所示，发现局部边缘区域得到了明显的 \n",
    "改善，趋近于原图的效果，边缘部分得到了明显的改蕃，其他未标注的边缘部分 \n",
    "也有或多或少的改善，说明边缘约束的方法可以显著提高边缘区域的分布和分类 \n",
    "效果。 \n",
    "50 基于贝叶斯框架的全卷积网络和显式边缘网络修正的SA民图懦分类 \n",
    "Bl 乂 ii＾Si ＾pwBP扇勝謂 \n",
    "，，下\n",
    " ，、t i、\n",
    " i .\n",
    " DT内部修正－de邱lAB (，t\n",
    " DT－deeplab\n",
    " 外部边缘修巧 \n",
    "图5.5边缘区域改善效果图 \n",
    "MMM \n",
    "己Bq \n",
    "■■ \n",
    "M3 \n",
    "ct。\n",
    " 1 . FCN－川；d边缘 ct DT－deeplab网络修正 \n",
    "圈5.6部分边缘k域巧细对比图 \n",
    "5.5本章小结 \n",
    "本章列举了实验的数据和其训练方法，对比了传统的CRF， SVM方法，引 \n",
    "入了 FCN8网络1＾及之后的各种改进网络或方法，详细分析了实验结果，也展示 \n",
    "了各种实验的结果，最后也对比了边缘区域结果和总体结果，证明了改进方法的 \n",
    "有效性。 \n",
    "51 武化大学硕±论文 \n",
    "6 总结与展望 \n",
    "6.1研究总结 \n",
    "本文主要解决SAR图像场景分割的问题，对于SAR伪彩图应用传统光学图 \n",
    "像的分割所用到的神经网络的方法，针对传统像素块加特征提取与分类器的传统 \n",
    "分割方法的诸多不足之处提出了改进思路，主要工作和贡献包括w下几方面： \n",
    "1)针对分类器的选择问题，抛弃传统的SVM， BP等分类器，选择适合图 \n",
    "像的分类器FCN8提离巧始分类正确率，FCN基于像素点直接分类，而像素块 \n",
    "方法在训练时是取块内类别占比最多的类别为其统一标号，预测是也是得到整个 \n",
    "区块的类别，对区块内的不同类别像素点采取忽略的态度，直接基于像素点的 \n",
    "FCN不存在此问题。 \n",
    "2)引入了 deeplab，利用CRF的特性引入周围像素点分类类别先验信息来 \n",
    "提高该点的分类正确率，将CRF作为后置可有效提髙分类正确率。 \n",
    "3)引入了 DT作为内部网络修正边缘。利用FCN边缘网络得到边缘分布和 \n",
    "边缘距离图，分别与DT的内部边缘网络输出融合后输入DT中，分析DT扩散 \n",
    "法效果不好的的核屯、问题并作出改进，然后结合改进的扩散法和补洞法进行外部 \n",
    "融合，加强了边缘分布的正确性，并提高了边缘附近区域像素点的类别正确率， \n",
    "也进一步提高了整体正确率。 \n",
    "4)重点分析了 DT网络效果不好的根本原因，包括扩散方向和扩散系数的 \n",
    "改进，确定扩散方向与边缘距离的关系，得到新的扩散系数方程，并加w强约束 \n",
    "条件，使得改进后的DT扩散法得到明显的提升，并外部结合FCN－hed边缘网 \n",
    "络得到的边缘，使得总体正确率和边缘区域得到显著改善。 \n",
    "巧在ESAR数据上进行实验验证，通过与经典的代表性方法SVM和CRF \n",
    "对比，从及FCN和其化后的改进网络，证明了结合FCN选缘网络和改进DT的 \n",
    "扩散法对整体结果和迪缘都有一定的改善，也改进了原DT网络的一些问题。 \n",
    "6.2展望 \n",
    "本文通过引入FCN等神经网络代替传统方法，提高了分类正确率，首先引 \n",
    "入了 deeplab优化了整体结果，然后针对DT网络的各种弊端提出了改进DT的 \n",
    "52 基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR困像分类 \n",
    "扩散方法，及用FCN－hed得到的边缘作为约束，又进一步提高了整体结果， \n",
    "但仍然存在一些关键的问题需要进一步改进和扩展。 \n",
    "1) FCN－hed边缘网络提出的边缘仍然不太精确，针对DT网络的实际效果 \n",
    "不显著的问题做出了分析找到了存在的关键问题并提出了对应的改进的扩散算 \n",
    "法，不过改进后的边缘融合算法也可再进一步改进。FCN8可以加上reSnet网 \n",
    "络进一步提高正确率。 \n",
    "2)特征提取在计算机图像处理中十分重要对结果也有着显著影响，但是本 \n",
    "文直接基于SAR图像的像素，没有进行符合SAR图像特性的预处理，如果在 \n",
    "FCN之前对像素做一些符合SAR雷达图像特性的适度变换和处理，那么最终的 \n",
    "结果可能有进一步的改善。 \n",
    "53  \n",
    "参考文献 \n",
    "川MAitreh.编，刹、洪等译.合成孔径雷达图像处理[M].电子工业出版社，2005. \n",
    "[2] J. S. lee And 巨.化tti化 AirBorne And SpAce－Borne polAriMetric SAR SyS1；eMS [M]. uSA： c民c \n",
    "preSS， 2009. \n",
    "[3] M. dABBoor，M. cohinS. An unSuperViSed clASSificAtion ApproAch for polAriMetric SA民 \n",
    "dAtA BASed on the chernoff diStAnce for coMpleX wiShArt diStr化ution [J]. ieee trAnSAction on \n",
    "geo化ience And reMo化 SenSing，2013， 51(7)：4200－4213. \n",
    "[4] J. J. VAn Zyl. unSuperViSed clASSificAtion of ScAttering MechAniSMS uSing Radar polAriMetry \n",
    "dAtA [J]. i巨巨e trAnSAction on geoScience And 艮eMot：e SenSing，l989， 27(l)：36－45. \n",
    "[5] S.民，Cloude And e. po打ier. An entropy BASed clASSificAtion ScheMe for lAnd ApplicAtionS of \n",
    "polAriMetric SA民[J]. ieee trAnSAction on geoScience And reMo化 SenSin呂，1997， 35(l)：68－78. \n",
    "[6] r f. lAurent， p. eric. unSuperViSed clASSificAtion of Multifrequency And fully polAriMetric \n",
    "SAR iMAgeS BASed on the H/alpha/AlphA＿wiShArt clASSifier [J]. lee目 trAnSAction on geoScience And \n",
    "民eMote SenSing， 2001，3900：2332－2342. \n",
    "[7] k.巨rSAhin， i. g. cuMMing，And 艮.k. wArd. SegMe打tAtion And dASSificAtio打 of polAriMetiic \n",
    "SA民 dAtA uSing SpectrAl grAph pArtitioning [J]， lee巨 trAnSAction on geoScience And reMot；e \n",
    "SenSing， 2010， 48(1)：164－174. \n",
    "[8] p. yu， A. k. qin， And d. A. clAuSi. polAriMetric SA民 iMAge SegMentAtion uSing region \n",
    "growing wi化 edge pe打Alty [JJ. i巨ee trAnSAction on geoScience And 民eMote SenSM径，2012， \n",
    "50(4)：1302－1317. \n",
    "[9] J. S. lee And M. r. gruneS. quAntitAtiVe corApAriS曰打 of clASSificAtion cApABility： fully \n",
    "polAriMetric VerSuS duAl And SinglepolAriZAtio打 SA民[J]. i因ee trAnSActio打 on geoScience And \n",
    "reMo化 SenSing，200]，39〇l)：2343－2351. \n",
    "[10]民.h＾nSch. coMpleX－VAlued M山ti－lAyer perceptronS—An ApplicAtion to polAriMetric SA民 \n",
    "dAtA [J]， phot；ogrAM engine reMo1：e SenSe，2010， 76巧)：1081－1088. \n",
    "[11] u. StefAn，k. SerkAn. iruegrAting c曰lor feAtureS in polAriMetric SA民 iMAge clASSificAtion [J]， \n",
    "ieee trAnSActio打 on geoScience And 民eMote SenSing， 2014， 52(4)：2197－2216. \n",
    "[12] J.民？ huynen. phenoMe打ologicAl l；heory of Radar tArgetS [d]. drukkeriJ Bronder－offSet，n. V.， \n",
    "民 otterdAM， 1970. \n",
    "[13] S. r. Cloude. group theory And polAriZAtion AlgeBrA [J]. optic， 1986， 75(l)：26－36. \n",
    "[14] e. krogAger. A 打ew decoMpoSition of the Radar tArg巧 ScAttering MAtriX [J]. electronicS \n",
    "letterS， 1990， 26(18)： 1525－1526. \n",
    "[15] A. freeMAn And S. l. durden. A 化i＇ee－coMponent ScAttering Model for polAriMetric SA艮 dAtA \n",
    "[J].祀e巨 trAnSAction on geo化ience And reMo1：e SenSing， 1998， 36(3)：963－973. \n",
    "[16] y. yAMAguchi， t. MoriyAMA. four－coMponent ScAttering Model for polAriMetric S人化 iMAge \n",
    "decoMpoSition [J]. ieee trAnSAction on geoScience And reMote SenSing， 2005， 43(8)； 1699－ \n",
    "1706. \n",
    "[17]艮.touZi. tArget ScAttering decoMpoSition in terMS of rou inVAriAnt tArget pArAMeterS [J]. \n",
    "i巨e巨 trAnSActio打 on geoScience And reMote SenSing， 2007， 45(1 )：73－84. \n",
    "[18] w. An，y. cui. three－coMpo打ent Model－BASed decoMpoSition for p曰lAriMetric SAR dAtA [J]. \n",
    "圧目巨 trA打SAction o打 geoScience And 民eMot；e SenSing，2010， 48(6)：2732－2739. \n",
    "[19] A. SAto， y. yAMAguchi，And g. Singh，＂four－coMponent ScAttering power decoMpoSition with \n",
    "eXtended VoluMe ScAttering Model [J]. ie巨e geoScience A打d 民eMote SenSing letterS，2012， \n",
    "9(2)：166－1170. \n",
    "[20] A. SAepuloh， k. koike. Applying BAyeSiAn deciSion clASSificAtion 化 pi－SA民 polAri－ Metric \n",
    "dAtA for detAiled eXtrAction of 化e geoMorphologic And StructurAl 传AtureS of An ActiVe VolcAno [J]. \n",
    "lee巨 trAnSAction on geoScience And 民eMote SenSing， 2012， 9(4)：554－ 558. \n",
    "[21] A. lonnqViSt， y.民AuS1；e. polAriMeiXic SA民 dAtA i打 lA打d coVer MApping i打 BoreAl Zone [J]. \n",
    "i巨e巨 trAnSAction on geoScie打ce And reMote Se打Sing， 2010， 48(10)：3652－3662. \n",
    "[22] c. eliA， S.民uSdno. SAR iMAge clASSificAtion through inforMAtion－theoretic teXturAl \n",
    "feAtureS， MRF SegMentAtion， And oBJect－orien1；ed leArning Vector quAntiZAtion [J]. ieee \n",
    "JournAl of Selected topicS in Applied eArth oBSerVAtionS And reMote SenSing， 2014， 7(4)： 1116－ \n",
    "1126. \n",
    "54 \n",
    "[23] A. VoiSin，V. A. kryloV. clASSificAtion of Very high reSo山tion SA民 iMAgeS of urBAn AreAS \n",
    "uSing copulAS And 怡Xture in A hierArchicAl Markov Random field Model [J]. i巨ee geoScience And \n",
    "reMote SenSing letterS， 2013， 10(1)；96－100. \n",
    "[24] M. SAlehi，y. MAghSoudi. iMproVing 比e AccurAcy of urBAn lAnd coVer clASSificAtion uSing \n",
    "RadarSAt－2 polSAR dAtA [J].旧巨e JournAl of Selected topicS in Applied eArth oBSerVAtionS And \n",
    "reMo kSenSMg，2014，7(4)：1394－140l \n",
    "[25] y. MAghSoudi，d. leckie. RadarSAt－2 polAriMetric SAR dAtA fBr BoreAl foreSt clASSificAtion \n",
    "uSing SVM And A wrApper feAtin＊e Select：or [J]. ieee JournAl of Select；ed topicS in Applied eArth \n",
    "oB化rVAtionS And reMo化 SenSing， 2013， 6(3)： 1531－1538. \n",
    "[26] X. Su，c. he. A SuperViSed clASSificAtion M別hod BASed on conditionAl Random fieldS wkh \n",
    "MukiScAle region connection cAlculuS Model for SAR iMAge [J]. lee巨 geoScience And reMoB \n",
    "SenSing letterS， 2011， 8(3)；497－50i. \n",
    "[27] g. ZhAng， X. JiA. SiMplified conditionAl Random fieldS with clASS BoundAry conStrAint for \n",
    "SpectrAl－SpAtiAl BASed reMote SenSing iMAge clASSificAtion [J]. ieee geoScience And reMoh \n",
    "SenSing letterS， 2012， ％5)：856－％0. \n",
    "[28] p. ZhAng， M. li. hierArchicAl conditionAl Random fieldS Model for SeMiSuperViSed SAR \n",
    "iMAge SegMentAtion [J]. ieee trAnSAction on geoScience And reMote SenSing， 2015， 53(4)； i－19. \n",
    "[29] f. deltAcquA. teXt；ure－BASed chArActeriZAtion of urBAn enVironMentS on SAtellite SAR \n",
    "iMAgeS [J]. ieee trAnSAction on geoScience And reMote SenSing， 2003， 41(1)： 153－159. \n",
    "[30] u. kAndASwAMy，d. A. AdJeroh. efficient teXture AnAlySiS of SAR iMAgery [J].旧ee \n",
    "trAnSAction on geoScience And reMol：e SenSin径，2005， 43(9)：20＾－2083. \n",
    "[31] g. AkBAriZAdeh. A new StAtiSticA＾BASed kutloSiS wAVelet 目nergy feA山re for teXt；u！＊e \n",
    "recognition of SAR iMAgeS [J]. ieee trAnSAction on geoScience And reMote SenSing， 2012， \n",
    "50(ll)：4358－4368. \n",
    "[32] p. plAninSic， J. Singh. SA民 iMAge cAtegoriZAtion uSing pArAMetric And nonpArAMetric \n",
    "ApproAcheS within A duAl tree cwt [J]. ieee geoScience And reMote SenSing letterS， 2014， \n",
    "n(10)：n57－1761. \n",
    "[33]民.deklcer. teXture AnAlySiS And clASSificAtion of 巨民S SAR iMAgeS fBr MAp updAtin呂 of urBAn \n",
    "AreAS in the netherlAndS [J]. ieee trAnSAction on geoScience And reMote SenSing， 2003， 41(9)： \n",
    "1950－1958. \n",
    "[34] d. dAi， w. yAng， And h. Sun. MultileVel locAl pAttern hiStogrAM for SAR iMAge clASSificAtion \n",
    "[J].化巨e geoScience And reMo化 SenSing letterS，201 ]，8(2)：225－229. \n",
    "[3引 Zi. qi， A. yeh，X. ll A noVel Algori化M for lAnd uSe And lAnd coVer clASSificAtion uSing \n",
    "民AdArSAt－2 polAriMetric SAR dAtA [J].民eMote SenSing of enVironMent， 2012，118：21－39. \n",
    "[36] M duquenoy， J. oVArleZ. SuperViSed clASSificAtion of ScAttererS on SAR iMAging BASed on \n",
    "incoherent polAriMetric tiMe－frequency SignAtui＊eS [c]. in proc. europeAn SignAl proceSSing \n",
    "conference， glASgow， ScotlAnd， 2009：764－768. \n",
    "[37] h. yin， y. cAo， And h. Sun. coMBining pyrAMid repreSentAtion And AdABooSt for urBAn \n",
    "Scene clASSificAtion uSing high－reSolution SyMhetic Aperture Radar iMAgeS uJ. Radar，SonAr ＆ \n",
    "nAVigAtion，let，2011，5(0：58－64. \n",
    "[38] q. deng，y. chen. coloriZAtion fBr polAriMetric SAR iMAge BASed on ScAtt巳ring MechAniSMS \n",
    "[A]. in proc. congr. iMAge SignAl p阳ceSS.，2008：697－701. \n",
    "[39] d. turner And i. h. woodhouSe. An icon－BASed Synoptic ViSuAliZAtion of fully polAriMetric \n",
    "Radar dA化[J]. reMo化 SenSing， 2012， 4(3)：648－660. \n",
    "[40] c. tiSon， f. tupin， And h. MAitre. A fuSion ScheMe for Joint retrieVAl of urBAn height MAp And \n",
    "clASSificAtion froM high－reSol山ion in化rferoMetric SAR iMAgeS [J].化ee tyAnSAction on \n",
    "geoScience And 民eMote SenSing， 2007， 45(2)：496－505. \n",
    "[41] J. d， wegner，r. h註nSch. Building de化ction froM one orthophol；o And high－reSolution inSA民 \n",
    "dAtA uSing conditionAl Random fieldS [J]. ieee JournAl of Selec化d topicS in Applied eArth \n",
    "oBSerVAtionS And reMo化 SenSin呂，2011，4(1)：83－91. \n",
    "[42] y－ ding，y. li. SAR iMAge clASSificAtion BASed on CRFS with in化grAtion of locAl lABd \n",
    "conteXt And pAirwiSe lABel coMpAtiBility [J]. ieee JournAl of Selected topicS in Applied eArth \n",
    "oBSerVAtionS And reMo化 SenSin邑，2014， 7(1 )：300－20t \n",
    "[43] y. lecun， B. BoSer， J. denker， d. henderSon， r. e. howArd，w. huBBArd， And l. d. JAckel. \n",
    "BAckpropAgAtion Applied to hAnd－wri打en Zip code recognition [J]. neu化1 coMputAtion，1989，1(4)： \n",
    "541－551. \n",
    "[44] kriZheVSky A，SutSkeVer i，hiMon g e. iMAgenet clASSificAtion wiui deep conVol山ionAl \n",
    "55  \n",
    "neurAl networkS[c]//AdVAnceS in neurAl inforMAtion proceSSing SySteMS. 2012； 1097－1105. \n",
    "[45] SiMonyAn k， ZiSSerMAn A. Very deep conVolutionAl networkS for lAi＊呂e－ScAle iMAge \n",
    "recognition＾]. ArXiV preprint ArXiV：h09.1556， 2014. \n",
    "[46] c. SZ巧ed乂 w. liu) y. JiA， p. SerMAnet， S. reed， d. AngueloV， d. erhAn， V. VAnhoucke， And \n",
    "A. rABinoVich. going deeper with conVolutionS[c]//proceedingS of the ieee conference on \n",
    "coMputer ViSion An过 pAttern 民ecognitkM. 2015： 1－9. \n",
    "[47] he k， ZhAng X，ren S，et Al. deep reSiduAl leArning for iMAge recognition[c]//proceedingS \n",
    "of the ieee conference on coMputer ViSion And pAttern recognition. 2016： 770－778. \n",
    "[48] Zheng S，JAyASuMAnA S，roMerA－pAredeS B， et Al. conditionAl 民AndoM fieldS AS recurrent \n",
    "neurAl networkS[c]// 2015 i巨ee internAtionAl con信rence on coMputer ViSion (iccV). SAntiAgo， \n",
    "chile：旧巨e coMp山er Society， 2015：1529－1537. \n",
    "[49] girShick r，日onAhue J， dArrdl t) et Al.民ich feAtuk hierArchieS fBr AccurAte oBJect \n",
    "detection And SeMAntic SegMentAtion＾]. 2014：580－587. \n",
    "[50] girShick r. fASt r－CNN[c]// 旧目e internAtionAl conference on coMp山er ViSion. i巨ee， \n",
    "2015：1440－1448. \n",
    "[5 u ren S， he k， girShick r， et Al－ fASter r－CNN： towArdS reAl－tiMe oBJect de1；ection whh \n",
    "re呂ion propoSAl networkS.[J]. ieee trAnSActionS on pAttern AnAlySiS ＆ MAchine iruelligence， \n",
    "2016：1－1. \n",
    "口叫 redMon J，diwAlA S， girShick r， et Ah you only look once： unified， reA＾tiMe oBJect \n",
    "detection＾]. 2016：779－788. \n",
    "[53] long， J， She化AMer，e， dArrell， t. fully conVolutionAl networkS for SeMAntic \n",
    "S巧MentAtion[c]// co讯puter ViSion And pAttern recognition (cVpr)， 2015 ieee conference on. \n",
    "BoS1：on，MASSAchuSettS：化ee，20] 5：1337－1342. \n",
    "[54] J. d. lAfferty，A. MccAlluM. conditionAl Random fieldS： proBABiliStic ModelS for SegMenting \n",
    "And lABeling Sequence dAtA [c]. in proc. of 化e internAtionAl con杞rence on MAchine leArning \n",
    "(icMl)， 2001：282－289. \n",
    "[55] dAVid M. Blei，Andi＊ew y. ng. lAtent dirichlet AllocAtion [J]. JournAl of MAchine leArning \n",
    "reSeArch ，2003 (3)： 993－1022. \n",
    "[56] c. he， t. Zhuo. nonlineAr coMpreSSed SenSing－BASed ldA topic Model for polAriMetric \n",
    "SA艮 iMA各e clASSiflcAtio打[J]. ieee JournAl of Selected topicS in Applied eArth oBSerVAtionS An过 \n",
    "艮eMote SenSing， 2014， 7(3)：972－982. \n",
    "[57]民.巨.SchApire. the BooSting ApproAch to MAchine leArning： An oVerView [叮 nonlineAr \n",
    "eStiMAtion And clASSificAtion， Springer， 2003， 171：149－17l. \n",
    "[58] ping Zhong， runSheng wAng， uSin呂 coMBinAtion of StAtiSticAl ModelS And MultileVel \n",
    "StructurAl inforMAtion for detecting urBAn AreAS froM A Single grAy－leVel iMAge[J]. geoScience \n",
    "And 民eMot；e SenSing， ie阿e trAr＼SActionS，2007， 45 巧)：M69 － 1482 . \n",
    "[59] S.kuMAr， M.heBert. diScriMinAtiVe Random fieldS： A diScriMinAtiVe frAMework for \n",
    "conteXtuAl interAction in clASSi巧cAtio打[c]. coMputer ViSion，iccV) 2003， 2： 1150—1157. \n",
    "[60] d. c. liu And J. nocedAl. on the liMited MeMory BfgS for lArge ScAle optiMiZAtion [J]. \n",
    "MAtheMAticAl pro呂rAMMing， 1989， 45(1 )：503－528. \n",
    "[61] dong，X.， ZhAng， y. SA民 iMAge reconStruction froM underSAMpled rAw dAtA uSing \n",
    "MAXiMuM A poSteriori eStiMAtion [J]. ieee JournAl of Selected topicS in Applied eArth \n",
    "oBSerVAtionS And 民eMo化 SenSin呂，2015， 8(4)： 1651 — 1664， \n",
    "[62] B. J. fr巧 And d. J. c. MAckAy. A reVolution： Belief propAgAtion in grAphS wi化 cyckS [M]. \n",
    "in neurAl inforMAtion proceSSing SyS化MS， BoSl：on，MA： Mit preSS， 1998， 10. \n",
    "[63]皮亦鸣，極建宇.合成孔径雷达成像原理[M].成都：电子科技大学出版社，2007. \n",
    "[64] chen l c， pApAndi＊eou g，kokkinoS i，et Al. SeMAntic iMA吕e SegMentAtion wil；h deep \n",
    "conVol加onAl netS And fully connected CRFS[J]. coMputer Science， 2014，8(4)：3巧－361. \n",
    "[65] chen l c， pApAndreou g， kokkinoS i， et Al. deeplab： SeMAntic iMAge SegMentAtion with \n",
    "deep conVolutionAl netS，AtrouS conVol山ion， And fully connec化d CRFS[J]. ArXiV preprint \n",
    "A 仿 iV：1606.00915，2016. \n",
    "[66] kJrAhenBqhl p，kol化n V. effident in信rence in f山ly connect；ed CRFS wi化 gAuSSiAn edge \n",
    "po化ntiAlS[c]// AdVAnceS in neurAl inforMAtion proceSSing SyShMS. harrAhS And hArVeyS， lAke \n",
    "tAhoe：nipS， 2012：109－117. \n",
    "[67] roSS S， Mu打02 d， heBert M，et Al. leArning MeSSAge－pASSing inference MAchineS 杞r \n",
    "Structured prediction[c]// ieee con耗rence on coMput：er ViSion 底 pAttern 民ecognition.colorAdo \n",
    "SpringS： i巨ee，2011：2737－2744 \n",
    "56 \n",
    "[68] StoyAnoV V，ropSon A，巨iS打er J. eMpiricAl riSk MiniMiZAtio打 of grAphicAl Model \n",
    "pArAMeterS giVen ApproXiMAte inference， decoding， And Model Structure[cV/ fourteen曲 \n",
    "internAtionAl confe 化打ce on ArtificiAl intelligence ＆ StAtiSticS. fort \n",
    "lAuderdAle，floridArAiStAtS，2011：725－733. \n",
    "[6別 l.－c. chen，g. pApAndreoA i. kokkinoS， k. Murphy，And A. l. y山lie. SeMAntic iMAge \n",
    "SegMentAtion with deep conVolutionAl netS And fully connected CRFS. in iclr， 2015. \n",
    "[70] e. S. l. gAStAl And M. M. oliVeirA. doMAin trAnSforM for edge－AwAre iMAge And Video \n",
    "proceSSing. in SiggrAph， 2011. \n",
    "[71] chen l c， BArron J t， pApAndreou g，巧 Al. SeMAntic iMAge SegMentAtion with tASk－Specific \n",
    "edge detection uSing CNNS And A diScriMinAtiVely trAined doMAin trAnSforM[c]//proceedingS of the \n",
    "ieee conference on coMputer ViSion And pAttern recognition. 2016： 4545－4554. \n",
    "[72] k. SiMonyAn And A.之iSSerMAn. Very deep conVolutionAl networkS for lArge－ScAle iMAge \n",
    "recognition. in iclr，2015. \n",
    "[73] k. cho， B. VAn Merri—enBoer，d. BAhdAnAu，And y. Bengio. on die propertieS of neurAl \n",
    "MAchine trAnSlAtion： encoder－decoder ApproAcheS. ArXiV：1409.1259， 2014. \n",
    "[74] d. h. huBei And t. n. wieSel. receptiVe fieldS， BinoculAr interAction And functionAl \n",
    "Architecture in the cAt＇S ViSuAl corteX. the JournAl of phySiology， 160(1)： 106－154， 1962. \n",
    "[75] d.MArr And e. ffildreth. theory of edge detection. proceedingS of 化e 艮oyAl Society of london. Serie泌.BiologicAl Sci州ceS， 207(1167)：187－217， iwo. \n",
    "[76] d？民.MArtin，c.c.fowlkeS，AndJ.MAuk. leAMingtodetect nAturAl iMAge BoundArieS uSing locAl \n",
    "BrightneSS， color， And teXture cueS. pAMi， 26(5)：530－549， 2004. \n",
    "[77] J. kittler. on the AccurAcy of the SoBel edge detector. iMAge And ViSion coMputing， i(l)：37－ \n",
    "42， 1983. \n",
    "[7巧 J. cAnny. A coMputAtionAl ApproAch 化 edge detection. pAMi， (6)：679－698， 1986. \n",
    "(7糾 r ArBelAeZJ M. MAire， c. fowlkeS， And J. MAlik. contour detection And hierArchicAliMAge \n",
    "SegMentAtion. pAMi， 33(5)：898－916， 2011. \n",
    "巧6] r dollAr， Z. tu， And S. Belongie. SuperViSed leArning of edgeS And oBJect BoundArieS. i打 \n",
    "cVpr， 2006. \n",
    "[81] J. J. liM，c. l. ZitnickJ And p. doll＇Ar. Sketch toke打S： A leArned Mid－leVel 化preSentAtio打 for \n",
    "contour And oBJect detection. in cVpr，2013. \n",
    "巧巧 p. doll＇Ar And c. l. Zitnick. fASt edge detection uSi打g Structured foreStS. pAMi，2015. \n",
    "[83] g. BertASiuS，J. Shi， And l. torreSAni. deepedge： A MultiScAle BifurcAted deep network for \n",
    "化p－down contour detection. in cVpr，2015. \n",
    "[84] J.－J.hwAngAnDT.－l丄iu？巧Xel－wiSedeepleArningfoi＂c〇ntour detection. in iclr，2015. \n",
    "巧5] Xie S， tu Z. holiSticAlly－neSted edge detection[c]// 旧ee internAtionAl conference on \n",
    "coMputer ViSion. ieee， 2015：13％－1403. \n",
    "巧6] k. SiMonyAn And A. ZiSSerMAn. Very deep conVol山ionAl networkS for lArge－ScAle iMAge \n",
    "recognition. in iclr，2015. \n",
    "巧7] r. Socher，B. huVAl， B. BAth， c. d. MAnnin呂，And A. y ng. conVolutio打Al－recurSiVe deep feAMing for 3d oBJect clASS！行cAtion. in nipS， 2012. \n",
    "[88]之.liu， X. li， p. luo， c. c. loy， And X. tAng. SeMAntic iMAge SegMentAtion ViA deep pArSing \n",
    "networic. in icctV，2015. \n",
    "巧9] 乂 MAghSoikii，d. leckie.艮AdArSAt－2 化lAriMetric SA民 dAtA for BoreAl foreSt clASSificAtion \n",
    "uSing SVM And A wrApper feAture Selector [J]. ieee JournAl of Selected topicS in Applied eArth \n",
    "oBSerVAtionS And reMo化 SenSing， 2013，6(3＾：1531－1538. \n",
    "[90] X. Su， c. he. A SuperViSed clASSificAtion Method BASed on conditionAl Random fieldS with \n",
    "MultiScAle region connection cAlculuS Model for SAR iMAge [J]. ieee geoScience And reMote \n",
    "SenSing letterS， 2011， 8(3)：497－501. \n",
    "57  \n",
    "攻读硕±期间科研项目和论文 \n",
    "？ ■参与的科研项目 \n",
    "山国家自然科学基金；高分辨率极化SAR图像特征提取和城区地物目标分 \n",
    "类研究(41371342) \n",
    "凹国家自然科学基金重点项目：高分辨率SAR图像城市目标认知解释与动 \n",
    "态监测应用研究(61331016) \n",
    "[3]国家重点基础研究发展计划(973计划)；复杂地表遥感信息动态分析与 \n",
    "建模(2013cB733404) \n",
    "[4]高分辨率对地观测系统重大专项(民用部分)：高分灾害监测与评估信息 \n",
    "服务应用示范系统(no.03－y30B06－9001－13/15) \n",
    "？发表的论文 \n",
    "叫汤乾何楚，＂全卷积网络结合改进的条件随巧减－循环神经网络用于SAR \n",
    "图像场景分类＂，计算机应用，2016 Vol. ％。巧：3436－3441。(核也期刊) \n",
    "58 \n",
    "致谢 \n",
    "一晃眼研究生h年时间即将过去，这兰年的学习时间让我获得了不少生活或 \n",
    "学习上的宝贵经验，从入学的刚从大学本科毕业的憎懂的新生，到现在对编程和 \n",
    "专业领域有一定了解和应用，这h年的学习和生活经历让我懂得了许多，也让\n",
    "w后的工作与生活有了新的起点和启示。 \n",
    "在此，我要感谢我在学习和生活中涨些帮助我的人。首先感谢我的父母，没 \n",
    "有他们任劳任怨，默默付出支付我的日常生活费，以及对我生活上无微不至的照 \n",
    "顾，我就不可能平稳完成我的学业。然后感谢我的导师何楚，他在我的学业和研 \n",
    "巧方向上给予了充足的支持和指导，每当我遇上学习或生活上的难题他都会帮助 \n",
    "我渡过难关。最后感谢舍友涂峰和实验室的其他师兄师妹们，他们在日常生活和 \n",
    "学习上，无私的不畏烦恼的帮助我处理了很多问题，鼓励我克服一些困难和生活 \n",
    "上的难题。 \n",
    "我一定不辜负其他帮助过我的人的期望，在{＾＾后的工作或学习中努为奋斗， \n",
    "争取有一定的成就和对社会做出力所能及的贡献。 \n",
    "汤浩 \n",
    "2017年4月11日 \n",
    "59 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "基于贝叶斯框架的全卷积网络和显式边缘网络修正的SAR图像分类",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
